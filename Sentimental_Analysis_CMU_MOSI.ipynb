{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentimental_Analysis_CMU_MOSI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPemu7Rz88dWusXEM2BNzO0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushabhinav/SentimentalAnalysis/blob/main/Sentimental_Analysis_CMU_MOSI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import os\n",
        "import requests\n",
        "import warnings\n",
        "import pickle as pkl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "S8aePNaLVj6M"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RR6zJqlItuN",
        "outputId": "013a1158-7373-4bc0-e521-4d1df85d4792"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Masking\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "XJtGloIUDCqJ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "tf.random.set_seed(24)"
      ],
      "metadata": {
        "id": "3CpZOhrTzKA1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download CMU_MOSI Data file\n",
        "data_file = 'mosi_data_50.pkl'\n",
        "\n",
        "if not os.path.exists(data_file):\n",
        "  res = requests.get('http://immortal.multicomp.cs.cmu.edu/raw_datasets/processed_data/cmu-mosi/seq_length_50/mosi_data.pkl')\n",
        "  with open(data_file , 'wb') as outfile:\n",
        "    outfile.write(res.content)\n",
        "\n",
        "# !wget http://immortal.multicomp.cs.cmu.edu/raw_datasets/processed_data/cmu-mosi/seq_length_50/mosi_data.pkl"
      ],
      "metadata": {
        "id": "PDTmeGkjQICW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mv mosi_data.pkl mosi_data_50.pkl\n",
        "!ls -lrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX086U24VfkG",
        "outputId": "99ca1cab-04e4-4955-d6a3-7b72bf602945"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 150436\n",
            "drwxr-xr-x 1 root root      4096 Jun  1 13:50 sample_data\n",
            "-rw-r--r-- 1 root root 154041300 Jun 12 06:42 mosi_data_50.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from pickled file\n",
        "data = None\n",
        "with open(data_file, 'rb') as infile:\n",
        "  data = pkl.load(infile)"
      ],
      "metadata": {
        "id": "Q-rjrZuxV2Zs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAVnpsjaWhrZ",
        "outputId": "2d436e0d-4f94-46d1-ae5c-e48b0e95181c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['valid', 'test', 'train'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seperate data in train, test and validation sets\n",
        "data_train = data['train']\n",
        "data_test = data['test']\n",
        "data_valid = data['valid']"
      ],
      "metadata": {
        "id": "jLdPPnUPXC7G"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmW7AQWUXXqm",
        "outputId": "8f34b203-656d-44fb-af1c-8a066d85a966"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['vision', 'labels', 'text', 'audio', 'id'])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# labels are here for the regesssion purpose\n",
        "data_train['labels']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo6iJ1z3aBek",
        "outputId": "7232c0e1-7be5-4c8c-d9e3-c1d178468d70"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.5]],\n",
              "\n",
              "       [[-1.2]],\n",
              "\n",
              "       [[ 1.8]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.6]],\n",
              "\n",
              "       [[-0.4]],\n",
              "\n",
              "       [[ 2. ]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.DataFrame({'id':data_valid['id']})\n",
        "valid_data_df = pd.DataFrame({\n",
        "                    'f_name': data_valid['id'][:,0],\n",
        "                    's_time': data_valid['id'][:,1],\n",
        "                    'e_time': data_valid['id'][:,2],\n",
        "                    'true_labels' : np.squeeze(data_valid['labels'][:,0] >= 0)\n",
        "                })\n",
        "valid_data_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OkGzSVQ3vx8u",
        "outputId": "e49ad10a-ff9e-4014-aebe-18d72bfab6cd"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                f_name          s_time          e_time  true_labels\n",
              "0    b'WKA5OygbEKI_20'  b'131.7929705'  b'133.6886621'         True\n",
              "1    b'WKA5OygbEKI_21'  b'133.6886621'   b'138.976644'         True\n",
              "2    b'WKA5OygbEKI_22'   b'170.544898'   b'172.729932'         True\n",
              "3     b'WKA5OygbEKI_1'  b'4.432426304'  b'8.852380952'         True\n",
              "4     b'WKA5OygbEKI_3'  b'45.95804989'  b'49.69954649'         True\n",
              "..                 ...             ...             ...          ...\n",
              "224   b'c5xsKMxpXnc_4'  b'133.2097506'  b'135.8836735'         True\n",
              "225   b'c5xsKMxpXnc_7'  b'149.3829932'  b'152.4360544'        False\n",
              "226   b'c5xsKMxpXnc_6'  b'146.7290249'  b'149.3829932'        False\n",
              "227   b'c5xsKMxpXnc_9'  b'156.6764172'  b'159.0609977'        False\n",
              "228   b'c5xsKMxpXnc_8'  b'154.1122449'  b'156.6764172'        False\n",
              "\n",
              "[229 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4f7584a-d06d-40dd-a8f1-bda174ac2414\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_name</th>\n",
              "      <th>s_time</th>\n",
              "      <th>e_time</th>\n",
              "      <th>true_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b'WKA5OygbEKI_20'</td>\n",
              "      <td>b'131.7929705'</td>\n",
              "      <td>b'133.6886621'</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b'WKA5OygbEKI_21'</td>\n",
              "      <td>b'133.6886621'</td>\n",
              "      <td>b'138.976644'</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b'WKA5OygbEKI_22'</td>\n",
              "      <td>b'170.544898'</td>\n",
              "      <td>b'172.729932'</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b'WKA5OygbEKI_1'</td>\n",
              "      <td>b'4.432426304'</td>\n",
              "      <td>b'8.852380952'</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b'WKA5OygbEKI_3'</td>\n",
              "      <td>b'45.95804989'</td>\n",
              "      <td>b'49.69954649'</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>b'c5xsKMxpXnc_4'</td>\n",
              "      <td>b'133.2097506'</td>\n",
              "      <td>b'135.8836735'</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>b'c5xsKMxpXnc_7'</td>\n",
              "      <td>b'149.3829932'</td>\n",
              "      <td>b'152.4360544'</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>b'c5xsKMxpXnc_6'</td>\n",
              "      <td>b'146.7290249'</td>\n",
              "      <td>b'149.3829932'</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>b'c5xsKMxpXnc_9'</td>\n",
              "      <td>b'156.6764172'</td>\n",
              "      <td>b'159.0609977'</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>b'c5xsKMxpXnc_8'</td>\n",
              "      <td>b'154.1122449'</td>\n",
              "      <td>b'156.6764172'</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>229 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4f7584a-d06d-40dd-a8f1-bda174ac2414')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4f7584a-d06d-40dd-a8f1-bda174ac2414 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4f7584a-d06d-40dd-a8f1-bda174ac2414');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis On the textual data as regression"
      ],
      "metadata": {
        "id": "I5deJ35FdTMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow.keras as keras\n",
        "# from tensorflow.keras.layers import Input, LSTM, Dense, Masking\n",
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "DHT9gbgAf8Jh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # function to build the model with different configuration\n",
        "# def get_model(n_unit=64, n_layer=1, mask_value=0.0, seq_len=50, latent_dim=300,\n",
        "#               model_name='model_name'):\n",
        "#   input_shape = (seq_len, latent_dim)\n",
        "#   mask_value = np.zeros(shape=(latent_dim,), dtype=np.float32)\n",
        "\n",
        "#   input = Input(shape=input_shape, name='input_layer')\n",
        "#   mask_lyr = Masking(mask_value=mask_value, name='masking_layer')\n",
        "\n",
        "#   layers = []\n",
        "#   for id in range(1, n_layer+1):\n",
        "#     if id != n_layer:\n",
        "#       layers.append(\n",
        "#           LSTM(n_unit, return_sequences=True, name=f'lstm_layer_{id}') \n",
        "#       )\n",
        "#     else:\n",
        "#       layers.append(\n",
        "#        LSTM(n_unit, return_sequences=False, name=f'lstm_layer_{id}')   \n",
        "#       )\n",
        "#   layers.append(\n",
        "#       Dense(1, activation='relu', name='dense_layer')\n",
        "#   )\n",
        "\n",
        "#   x = mask_lyr(input)\n",
        "#   for layer in layers:\n",
        "#     x = layer(x)\n",
        "\n",
        "#   model = Model(inputs=input, outputs=x, name=model_name)\n",
        "#   return model\n"
      ],
      "metadata": {
        "id": "0BwpdDURL6DG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # preparing the data for training\n",
        "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "# buffer_size = 64\n",
        "# batch_size = 64\n",
        "\n",
        "# train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "#                 (\n",
        "#                     data_train['text'], \n",
        "#                     data_train['labels']\n",
        "#                 )\n",
        "#             ).map(lambda x,y: (x, y+3)) \\\n",
        "#             .shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "# valid_ds = tf.data.Dataset.from_tensor_slices(\n",
        "#                 (\n",
        "#                     data_valid['text'],\n",
        "#                     data_valid['labels']\n",
        "#                 )\n",
        "#             ).map(lambda x,y: (x, y+3)) \\\n",
        "#             .shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "ht9eHywziBkg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for data in train_ds.take(1):\n",
        "#   print(data)"
      ],
      "metadata": {
        "id": "KZiy0QiT3J5d"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # compile the model\n",
        "# def compile_model(model):\n",
        "\n",
        "#   optimizer = tf.keras.optimizers.Adam()\n",
        "#   loss = tf.keras.losses.MeanSquaredError()\n",
        "#   metrics = tf.keras.metrics.RootMeanSquaredError()\n",
        "\n",
        "\n",
        "#   model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "#   print(f'Model-{model.name} is compiled successfully')"
      ],
      "metadata": {
        "id": "Iz2gXBLbbTH2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # train and plot losses\n",
        "# def train_plot_result(model, train_ds=train_ds, val_ds=valid_ds, epochs=500, verbose=1, **kwargs):\n",
        "#     file_path = os.path.join(os.getcwd(), f'{model.name}_checkpoint')\n",
        "#     if not os.path.exists(file_path):\n",
        "#       os.makedirs(file_path)\n",
        "\n",
        "#     early_stopping   = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "#     model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=file_path, save_best_only=True)\n",
        "#     callbacks = [early_stopping, model_checkpoint]\n",
        "\n",
        "#     history = model.fit(train_ds, epochs=epochs, validation_data=valid_ds, callbacks=callbacks,verbose=verbose, **kwargs)\n",
        "    \n",
        "#     loss = history.history['loss']\n",
        "#     val_loss = history.history['val_loss']\n",
        "\n",
        "#     plt.plot(loss, label='train_loss')\n",
        "#     plt.plot(val_loss, label='val_loss')\n",
        "#     plt.legend()\n",
        "#     plt.title(f'{model.name} losses')\n",
        "#     plt.show()\n",
        "#     return history"
      ],
      "metadata": {
        "id": "-Frbs_EDSAkc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # plot correctness of pred wrt actual value\n",
        "# def check_correctness(model, data_X, data_y):\n",
        "\n",
        "#   y_pred = np.squeeze(np.ceil(model(data_X)))\n",
        "#   y_true = np.squeeze( np.ceil(data_y) )\n",
        "\n",
        "#   true_match = sum(y_pred == y_true)\n",
        "#   print(f'Accuracy: {round(true_match * 100 /len(y_pred), 2)}%')\n",
        "\n",
        "#   plt.title('Pred Vs Actual Classes Matching')\n",
        "#   sns.countplot(y_pred == y_true )\n",
        "#   plt.show()\n",
        "\n",
        "#   plt.title('Pred Class Count')\n",
        "#   sns.countplot(y_pred)\n",
        "#   plt.show()\n",
        "\n",
        "#   plt.title('Actual Class Count ')\n",
        "#   sns.countplot(y_true)\n",
        "#   plt.show()"
      ],
      "metadata": {
        "id": "5CL0k4SpVtdY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model - 1LSTM64"
      ],
      "metadata": {
        "id": "diGocUBhYWFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model1 = get_model(model_name='Basic_Model-1LSTM64')\n",
        "# model1.summary()"
      ],
      "metadata": {
        "id": "yJ3jGxKGWlJ9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile_model(model1)\n",
        "# train_plot_result(model1)\n",
        "# # model1.fit(train_ds, validation_data=valid_ds, epochs=50)"
      ],
      "metadata": {
        "id": "DYgy3_ATW5Yv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check_correctness(model1, data_train['text'], data_train['labels'])"
      ],
      "metadata": {
        "id": "IKtE4VywYJOX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model 2LSTM64"
      ],
      "metadata": {
        "id": "qhGpSSY4YrDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model2 = get_model(model_name='Basic_Model_2LSTM64', n_unit=64, n_layer=2)\n",
        "# compile_model(model2)"
      ],
      "metadata": {
        "id": "bZTrmLJBspzv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model2.summary()"
      ],
      "metadata": {
        "id": "y1l9cGgwZgSB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_plot_result(model2)"
      ],
      "metadata": {
        "id": "-7BPdUjmY_HQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check_correctness(model2, data_train['text'], data_train['labels'])"
      ],
      "metadata": {
        "id": "mHEfTuVLZDDg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### model 1lSTM128"
      ],
      "metadata": {
        "id": "Zsb9rcQIZuOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model3 = get_model(model_name='Basic_Model_1LSTM128', n_unit=128)\n",
        "# compile_model(model3)"
      ],
      "metadata": {
        "id": "y0F9g-9oZl2W"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_plot_result(model3)"
      ],
      "metadata": {
        "id": "VVt44CCMaAn7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check_correctness(model3, data_train['text'], data_train['labels'])"
      ],
      "metadata": {
        "id": "zO2YJ7LPaFQg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Model 2LSTM128"
      ],
      "metadata": {
        "id": "bPOOhZd5bUzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model4 = get_model(model_name='Basic_Model_2LSTM128', n_unit=128, n_layer=2)\n",
        "# compile_model(model4)"
      ],
      "metadata": {
        "id": "orbogQonbQyP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_plot_result(model4)"
      ],
      "metadata": {
        "id": "dNruUufGaKAY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check_correctness(model4, data_train['text'], data_train['labels'])"
      ],
      "metadata": {
        "id": "710QQAl7bl_L"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### model 1LSTM256"
      ],
      "metadata": {
        "id": "4gQkVlV3dW_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model5 = get_model(model_name='Basic_Model_1LSTM256', n_unit=256)\n",
        "# compile_model(model5)"
      ],
      "metadata": {
        "id": "H2YRW_prbrHG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_plot_result(model5)"
      ],
      "metadata": {
        "id": "4YQHH9pXdrti"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check_correctness(model5, data_train['text'], data_train['labels'])"
      ],
      "metadata": {
        "id": "3iqxcUd8duHX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### model 2LSTM256"
      ],
      "metadata": {
        "id": "pwRaUzv8eWFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model6 = get_model(model_name='Basic_Model_2LSTM256', n_unit=256, n_layer=2)\n",
        "# compile_model(model6)"
      ],
      "metadata": {
        "id": "ULxDxkf4dyKH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_plot_result(model6)"
      ],
      "metadata": {
        "id": "5vR5-4Owej-Y"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check_correctness(model6, data_train['text'], data_train['labels'])"
      ],
      "metadata": {
        "id": "wbk6OPvzenaS"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding Attention Layer"
      ],
      "metadata": {
        "id": "vy3ubvNY4CQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Method 1"
      ],
      "metadata": {
        "id": "9tU-ItNYC0J0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras import initializers, regularizers, constraints\n",
        "\n",
        "def dot_product(x, kernel):\n",
        "    \"\"\"\n",
        "    Wrapper for dot product operation, in order to be compatible with both\n",
        "    Theano and Tensorflow\n",
        "    Args:\n",
        "        x (): input\n",
        "        kernel (): weights\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "    if K.backend() == 'tensorflow':\n",
        "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
        "    else:\n",
        "        return K.dot(x, kernel)\n",
        "\n",
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Attention operation, with a context/query vector, for temporal data.\n",
        "    Supports Masking.\n",
        "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
        "    \"Hierarchical Attention Networks for Document Classification\"\n",
        "    by using a context vector to assist the attention\n",
        "    # Input shape\n",
        "        3D tensor with shape: `(samples, steps, features)`.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(samples, features)`.\n",
        "    How to use:\n",
        "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "    The dimensions are inferred based on the output shape of the RNN.\n",
        "    Note: The layer has been tested with Keras 2.0.6\n",
        "    Example:\n",
        "        model.add(LSTM(64, return_sequences=True))\n",
        "        model.add(AttentionWithContext())\n",
        "        # next add a Dense layer (for classification/regression) or whatever...\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.u_regularizer = regularizers.get(u_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.u_constraint = constraints.get(u_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(name='w', shape=(input_shape[-1], input_shape[-1],),\n",
        "                                 initializer='normal' )\n",
        "                                #  initializer=self.init,\n",
        "                                #  name='{}_W'.format('w'), #self.name),\n",
        "                                #  regularizer=self.W_regularizer,\n",
        "                                #  constraint=self.W_constraint)\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight(name='b', shape=(input_shape[-1],),\n",
        "                                     initializer='zero')\n",
        "                                    #  name='{}_b'.format('b'), #self.name),\n",
        "                                    #  regularizer=self.b_regularizer,\n",
        "                                    #  constraint=self.b_constraint)\n",
        "\n",
        "        self.u = self.add_weight(name='u', shape=(input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                #  name='{}_u'.format('u'), #self.name),\n",
        "                                 regularizer=self.u_regularizer,\n",
        "                                 constraint=self.u_constraint)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        uit = dot_product(x, self.W)\n",
        "\n",
        "        if self.bias:\n",
        "            uit += self.b\n",
        "\n",
        "        uit = K.tanh(uit)\n",
        "        ait = dot_product(uit, self.u)\n",
        "\n",
        "        a = K.exp(ait)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
        "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[-1]"
      ],
      "metadata": {
        "id": "hFILGypU5ZYl"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Method 2"
      ],
      "metadata": {
        "id": "FoLUx0p5C3ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.w = self.add_weight(shape=(input_shape[-1], 1), initializer='normal')\n",
        "    self.b = self.add_weight(shape=(input_shape[-2], 1), initializer='zeros')\n",
        "    super().build(input_shape)\n",
        "\n",
        "  def call(self, x):\n",
        "    a = K.tanh(K.dot(x,self.w) + self.b)\n",
        "    a = K.softmax(a, axis=1)\n",
        "    output = x * a\n",
        "\n",
        "    return a, K.sum(output, axis=1)"
      ],
      "metadata": {
        "id": "HhlW0M3FdncZ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis On the textual data as Classification"
      ],
      "metadata": {
        "id": "3o21W0hYlgnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing the data for training\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "buffer_size = 64\n",
        "batch_size = 64\n",
        "\n",
        "#############################################\n",
        "##### Dataset for Binary Classification #####\n",
        "#############################################\n",
        "\n",
        "train_binary_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    data_train['text'], \n",
        "                    data_train['labels']\n",
        "                )\n",
        "            ).map(lambda x,y: (x,[1, 0]) if y < 0 else (x,[0,1])).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "valid_binary_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    data_valid['text'],\n",
        "                    data_valid['labels']\n",
        "                )\n",
        "            ).map(lambda x,y: (x,[1, 0]) if y < 0 else (x,[0,1])).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "test_binary_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    data_test['text'],\n",
        "                    data_test['labels']\n",
        "                )\n",
        "            ).map(lambda x,y: (x,[1, 0]) if y < 0 else (x,[0,1])).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "\n",
        "#################################################\n",
        "##### Dataset for Multiclass Classification #####\n",
        "#################################################\n",
        "\n",
        "def convert_one_hot(x, y):\n",
        "  y = tf.squeeze(y)\n",
        "  return (x, tf.one_hot(tf.cast(tf.floor(y+3), tf.int64), 7))\n",
        "\n",
        "train_multi_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    data_train['text'], \n",
        "                    data_train['labels']\n",
        "                )\n",
        "            ).map(convert_one_hot).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "valid_multi_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    data_valid['text'],\n",
        "                    data_valid['labels']\n",
        "                )\n",
        "            ).map(convert_one_hot).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "test_multi_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    data_test['text'],\n",
        "                    data_test['labels']\n",
        "                )\n",
        "            ).map(convert_one_hot).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "6a2IJ5AQl9hy"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for data in train_class_ds.take(1):\n",
        "#   print(data)"
      ],
      "metadata": {
        "id": "lgEeFuXQqlA0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to build the model with different configuration\n",
        "def get_classification_model(n_unit=64, n_layer=1, n_class=2, seq_len=50, \n",
        "                             latent_dim=300, name='model_name'):\n",
        "  input_shape = (seq_len, latent_dim)\n",
        "  mask_value = np.zeros(shape=[latent_dim,], dtype=np.float32)\n",
        "  input = Input(shape=input_shape, name='input_layer')\n",
        "  mask_lyr = Masking(mask_value=mask_value, name='masking_layer')\n",
        "\n",
        "  layers = []\n",
        "  for id in range(1, n_layer+1):\n",
        "    if id != n_layer:\n",
        "      layers.append(\n",
        "          LSTM(n_unit, return_sequences=True, dropout=0.4, name=f'lstm_layer_{id}') \n",
        "      )\n",
        "    else:\n",
        "      layers.append(\n",
        "       LSTM(n_unit, return_sequences=False, dropout=0.4, name=f'lstm_layer_{id}')   \n",
        "      )\n",
        "  \n",
        "  layers.append(\n",
        "      Dense(n_class, activation='softmax', name='dense_layer_2')\n",
        "  )\n",
        "\n",
        "\n",
        "  x = mask_lyr(input)\n",
        "  for layer in layers:\n",
        "    x = layer(x)\n",
        "\n",
        "  model = Model(inputs=input, outputs=x, name=name)\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "aFkxgtBBl9hy"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "def compile_classification_model(model, optimizer='adam', loss='categorical_crossentropy', metrics='accuracy'):\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "  print(f'Model-{model.name} is compiled successfully')"
      ],
      "metadata": {
        "id": "iYHBVBTNl9hz"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_model_1 = get_classification_model(name= 'Basic_C_model_1', n_unit=256, n_layer=1)\n",
        "compile_classification_model(c_model_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLi7Wdn2tm2u",
        "outputId": "9b0a1c17-fe54-4357-c72f-36c0a93e6071"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model-Basic_C_model_1 is compiled successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5cnXVdculIf",
        "outputId": "18582d22-7a67-413f-c12b-33da66c62453"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Basic_C_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 50, 300)]         0         \n",
            "                                                                 \n",
            " masking_layer (Masking)     (None, 50, 300)           0         \n",
            "                                                                 \n",
            " lstm_layer_1 (LSTM)         (None, 256)               570368    \n",
            "                                                                 \n",
            " dense_layer_2 (Dense)       (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 570,882\n",
            "Trainable params: 570,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_model_1.fit(train_binary_ds, validation_data=valid_binary_ds, epochs=50, callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yih57UR4uMVU",
        "outputId": "dd08bb8d-8f9a-422b-d9ad-a6e8aac79828"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "21/21 [==============================] - 22s 541ms/step - loss: 0.6679 - accuracy: 0.5997 - val_loss: 0.7671 - val_accuracy: 0.4934\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 8s 368ms/step - loss: 0.6360 - accuracy: 0.6269 - val_loss: 0.6185 - val_accuracy: 0.6201\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 8s 377ms/step - loss: 0.6080 - accuracy: 0.6558 - val_loss: 0.5765 - val_accuracy: 0.6856\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 8s 380ms/step - loss: 0.5363 - accuracy: 0.7352 - val_loss: 0.5773 - val_accuracy: 0.7031\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 8s 380ms/step - loss: 0.5217 - accuracy: 0.7344 - val_loss: 0.6639 - val_accuracy: 0.6157\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 8s 379ms/step - loss: 0.5610 - accuracy: 0.7033 - val_loss: 0.5452 - val_accuracy: 0.7118\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 8s 373ms/step - loss: 0.4865 - accuracy: 0.7687 - val_loss: 0.6104 - val_accuracy: 0.6856\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 8s 377ms/step - loss: 0.5097 - accuracy: 0.7453 - val_loss: 0.5585 - val_accuracy: 0.6856\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 8s 396ms/step - loss: 0.4402 - accuracy: 0.8014 - val_loss: 0.5895 - val_accuracy: 0.7074\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 8s 372ms/step - loss: 0.4179 - accuracy: 0.8084 - val_loss: 0.6065 - val_accuracy: 0.7118\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 8s 378ms/step - loss: 0.4181 - accuracy: 0.8107 - val_loss: 0.6033 - val_accuracy: 0.6638\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.3759 - accuracy: 0.8341 - val_loss: 0.6245 - val_accuracy: 0.6725\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 9s 434ms/step - loss: 0.3839 - accuracy: 0.8294 - val_loss: 0.6172 - val_accuracy: 0.6856\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 8s 373ms/step - loss: 0.3474 - accuracy: 0.8411 - val_loss: 0.5842 - val_accuracy: 0.7162\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 8s 378ms/step - loss: 0.3145 - accuracy: 0.8668 - val_loss: 0.6227 - val_accuracy: 0.6987\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 8s 387ms/step - loss: 0.2932 - accuracy: 0.8738 - val_loss: 0.5902 - val_accuracy: 0.7205\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc14d2e5c10>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_model_1.evaluate(test_binary_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT1Q4f3hL2iY",
        "outputId": "0497e4d6-8d39-4891-b196-5ac64ab23685"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 2s 132ms/step - loss: 0.5825 - accuracy: 0.7041\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5825050473213196, 0.704081654548645]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_seq_len = 50\n",
        "t_latent_dim = 300\n",
        "\n",
        "t_input_shape = (t_seq_len, t_latent_dim)\n",
        "t_mask_value = np.zeros(shape=[300,], dtype=np.float32)\n",
        "\n",
        "t_input = Input(shape=t_input_shape, name='text_input_layer')\n",
        "t_mask_lyr = Masking(mask_value=t_mask_value, name='text_masking_layer')\n",
        "t_lstm_lyr = LSTM(256, return_sequences=True, name='text_lstm_layer_1')\n",
        "t_att_lyr = AttentionLayer()\n",
        "t_dense_lyr_1 = Dense(32, activation='relu', name='text_dense_layer_1')\n",
        "t_dense_lyr_2 = Dense(2, activation='softmax', name='text_dense_layer_2')\n",
        "\n",
        "\n",
        "mask_op = t_mask_lyr(t_input)\n",
        "all_states = t_lstm_lyr(mask_op)\n",
        "att_we, att_op = t_att_lyr(all_states)  \n",
        "x = t_dense_lyr_1(att_op)\n",
        "dense_op = t_dense_lyr_2(x)\n",
        "\n",
        "t_model = Model(inputs=t_input, outputs=dense_op)"
      ],
      "metadata": {
        "id": "jFkDxfI-w6L1"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieeeVojFxciU",
        "outputId": "0d758da3-830f-48bb-8af5-b3166fce6a18"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_input_layer (InputLaye  [(None, 50, 300)]        0         \n",
            " r)                                                              \n",
            "                                                                 \n",
            " text_masking_layer (Masking  (None, 50, 300)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " text_lstm_layer_1 (LSTM)    (None, 50, 256)           570368    \n",
            "                                                                 \n",
            " attention_layer (AttentionL  ((None, 50, 1),          306       \n",
            " ayer)                        (None, 256))                       \n",
            "                                                                 \n",
            " text_dense_layer_1 (Dense)  (None, 32)                8224      \n",
            "                                                                 \n",
            " text_dense_layer_2 (Dense)  (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 578,964\n",
            "Trainable params: 578,964\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
        "t_model.fit(train_binary_ds, validation_data=valid_binary_ds, epochs=50, callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRN_IHhbyc2V",
        "outputId": "03ee94e3-22de-46b9-c138-9e31c1ce381d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "21/21 [==============================] - 21s 559ms/step - loss: 0.6955 - accuracy: 0.5498 - val_loss: 0.6868 - val_accuracy: 0.5808\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 8s 373ms/step - loss: 0.6793 - accuracy: 0.6012 - val_loss: 0.7262 - val_accuracy: 0.5328\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.6891 - accuracy: 0.5717 - val_loss: 0.6639 - val_accuracy: 0.6070\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 8s 367ms/step - loss: 0.6615 - accuracy: 0.6464 - val_loss: 0.6404 - val_accuracy: 0.6070\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.6034 - accuracy: 0.6830 - val_loss: 0.6908 - val_accuracy: 0.6201\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 8s 370ms/step - loss: 0.6250 - accuracy: 0.6519 - val_loss: 0.6364 - val_accuracy: 0.6638\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 8s 366ms/step - loss: 0.6015 - accuracy: 0.6791 - val_loss: 0.5968 - val_accuracy: 0.7118\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 8s 370ms/step - loss: 0.5902 - accuracy: 0.6978 - val_loss: 0.5848 - val_accuracy: 0.6943\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 8s 373ms/step - loss: 0.5066 - accuracy: 0.7516 - val_loss: 0.6774 - val_accuracy: 0.6943\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 9s 420ms/step - loss: 0.5362 - accuracy: 0.7274 - val_loss: 0.5551 - val_accuracy: 0.7467\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 8s 373ms/step - loss: 0.5233 - accuracy: 0.7477 - val_loss: 0.5464 - val_accuracy: 0.7336\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 8s 367ms/step - loss: 0.4442 - accuracy: 0.8006 - val_loss: 0.5740 - val_accuracy: 0.7336\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.4329 - accuracy: 0.8030 - val_loss: 0.5366 - val_accuracy: 0.7598\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 8s 371ms/step - loss: 0.3842 - accuracy: 0.8326 - val_loss: 0.6041 - val_accuracy: 0.7336\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 8s 364ms/step - loss: 0.3992 - accuracy: 0.8146 - val_loss: 0.5384 - val_accuracy: 0.7773\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 8s 372ms/step - loss: 0.3634 - accuracy: 0.8364 - val_loss: 0.5644 - val_accuracy: 0.7686\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 8s 372ms/step - loss: 0.3224 - accuracy: 0.8575 - val_loss: 0.5974 - val_accuracy: 0.7860\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 9s 422ms/step - loss: 0.2909 - accuracy: 0.8762 - val_loss: 0.6128 - val_accuracy: 0.7948\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 8s 367ms/step - loss: 0.2461 - accuracy: 0.8894 - val_loss: 0.6959 - val_accuracy: 0.7948\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 8s 371ms/step - loss: 0.2229 - accuracy: 0.9011 - val_loss: 0.5683 - val_accuracy: 0.7686\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 8s 366ms/step - loss: 0.2085 - accuracy: 0.9097 - val_loss: 0.7017 - val_accuracy: 0.7817\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 8s 369ms/step - loss: 0.1588 - accuracy: 0.9322 - val_loss: 0.8606 - val_accuracy: 0.7729\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 8s 377ms/step - loss: 0.1379 - accuracy: 0.9424 - val_loss: 0.9774 - val_accuracy: 0.7642\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc14c124850>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_model.evaluate(test_binary_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy2hint5vW5l",
        "outputId": "91b76f27-b006-4b07-cd17-c9077575967d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 2s 132ms/step - loss: 0.5150 - accuracy: 0.7653\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5150203108787537, 0.7653061151504517]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data_df['t_model'] = t_model.predict(data_valid['text'])[:,1] >= 0.5\n",
        "valid_data_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ObL1qaWhugiD",
        "outputId": "e4d04e08-ced9-45c9-dc0f-f1bca1ece05e"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                f_name          s_time          e_time  true_labels  t_model\n",
              "0    b'WKA5OygbEKI_20'  b'131.7929705'  b'133.6886621'         True     True\n",
              "1    b'WKA5OygbEKI_21'  b'133.6886621'   b'138.976644'         True    False\n",
              "2    b'WKA5OygbEKI_22'   b'170.544898'   b'172.729932'         True     True\n",
              "3     b'WKA5OygbEKI_1'  b'4.432426304'  b'8.852380952'         True     True\n",
              "4     b'WKA5OygbEKI_3'  b'45.95804989'  b'49.69954649'         True     True\n",
              "..                 ...             ...             ...          ...      ...\n",
              "224   b'c5xsKMxpXnc_4'  b'133.2097506'  b'135.8836735'         True     True\n",
              "225   b'c5xsKMxpXnc_7'  b'149.3829932'  b'152.4360544'        False    False\n",
              "226   b'c5xsKMxpXnc_6'  b'146.7290249'  b'149.3829932'        False    False\n",
              "227   b'c5xsKMxpXnc_9'  b'156.6764172'  b'159.0609977'        False    False\n",
              "228   b'c5xsKMxpXnc_8'  b'154.1122449'  b'156.6764172'        False    False\n",
              "\n",
              "[229 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df101a7a-8e2a-4d9a-ab58-a56aaaf7463a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_name</th>\n",
              "      <th>s_time</th>\n",
              "      <th>e_time</th>\n",
              "      <th>true_labels</th>\n",
              "      <th>t_model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b'WKA5OygbEKI_20'</td>\n",
              "      <td>b'131.7929705'</td>\n",
              "      <td>b'133.6886621'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b'WKA5OygbEKI_21'</td>\n",
              "      <td>b'133.6886621'</td>\n",
              "      <td>b'138.976644'</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b'WKA5OygbEKI_22'</td>\n",
              "      <td>b'170.544898'</td>\n",
              "      <td>b'172.729932'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b'WKA5OygbEKI_1'</td>\n",
              "      <td>b'4.432426304'</td>\n",
              "      <td>b'8.852380952'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b'WKA5OygbEKI_3'</td>\n",
              "      <td>b'45.95804989'</td>\n",
              "      <td>b'49.69954649'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>b'c5xsKMxpXnc_4'</td>\n",
              "      <td>b'133.2097506'</td>\n",
              "      <td>b'135.8836735'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>b'c5xsKMxpXnc_7'</td>\n",
              "      <td>b'149.3829932'</td>\n",
              "      <td>b'152.4360544'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>b'c5xsKMxpXnc_6'</td>\n",
              "      <td>b'146.7290249'</td>\n",
              "      <td>b'149.3829932'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>b'c5xsKMxpXnc_9'</td>\n",
              "      <td>b'156.6764172'</td>\n",
              "      <td>b'159.0609977'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>b'c5xsKMxpXnc_8'</td>\n",
              "      <td>b'154.1122449'</td>\n",
              "      <td>b'156.6764172'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>229 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df101a7a-8e2a-4d9a-ab58-a56aaaf7463a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df101a7a-8e2a-4d9a-ab58-a56aaaf7463a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df101a7a-8e2a-4d9a-ab58-a56aaaf7463a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(valid_data_df.true_labels == valid_data_df.t_model) / valid_data_df.t_model.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YlPwm3TvMBn",
        "outputId": "3c8b2d35-8725-4ee5-f306-fe007d7e77bc"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.759825327510917"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis on Visual Data for classification"
      ],
      "metadata": {
        "id": "93KCwDaUPd_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train['vision'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEhu-QulPkei",
        "outputId": "2da46786-e5fe-4961-876b-42f21cadf5e5"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1284, 50, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing the data for training\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "buffer_size = 64\n",
        "batch_size = 64\n",
        "\n",
        "#############################################\n",
        "##### Dataset for Binary Classification #####\n",
        "#############################################\n",
        "\n",
        "train_visual_binary_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    data_train['vision'], \n",
        "                    data_train['labels']\n",
        "                )\n",
        "            ).map(lambda x,y: (x,[1, 0]) if y < 0 else (x,[0,1])).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "valid_visual_binary_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    data_valid['vision'],\n",
        "                    data_valid['labels']\n",
        "                )\n",
        "            ).map(lambda x,y: (x,[1, 0]) if y < 0 else (x,[0,1])).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "test_visual_binary_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    data_test['vision'],\n",
        "                    data_test['labels']\n",
        "                )\n",
        "            ).map(lambda x,y: (x,[1, 0]) if y < 0 else (x,[0,1])).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "\n",
        "#################################################\n",
        "##### Dataset for Multiclass Classification #####\n",
        "#################################################\n",
        "\n",
        "def convert_one_hot(x, y):\n",
        "  y = tf.squeeze(y)\n",
        "  return (x, tf.one_hot(tf.cast(tf.floor(y+3), tf.int64), 7))\n",
        "\n",
        "train_visual_multi_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    data_train['vision'], \n",
        "                    data_train['labels']\n",
        "                )\n",
        "            ).map(convert_one_hot).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "valid_visual_multi_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    data_valid['vision'],\n",
        "                    data_valid['labels']\n",
        "                )\n",
        "            ).map(convert_one_hot).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "test_visual_multi_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    data_test['vision'],\n",
        "                    data_test['labels']\n",
        "                )\n",
        "            ).map(convert_one_hot).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "1yZ8vfZrTQQc"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################\n",
        "##### Classification Model on visual Data   #####\n",
        "#################################################\n",
        "\n",
        "v_seq_len = 50\n",
        "v_latent_dim = 20\n",
        "\n",
        "v_input_shape = (v_seq_len, v_latent_dim)\n",
        "v_mask_value = np.zeros(shape=(v_latent_dim,), dtype=np.float32)\n",
        "\n",
        "v_input = Input(shape=v_input_shape, name='v_input_layer')\n",
        "v_mask_lyr = Masking(mask_value=v_mask_value, name='v_mask_layer')\n",
        "v_lstm_lyr = LSTM(256, return_sequences=False, dropout=0.4, name='v_lstm_layer_1')\n",
        "v_dense_lyr = Dense(2, activation='softmax', name='v_dense_layer')\n",
        "\n",
        "\n",
        "x = v_mask_lyr(v_input)\n",
        "x = v_lstm_lyr(x)\n",
        "x = v_dense_lyr(x)\n",
        "\n",
        "v_model = Model(inputs=v_input, outputs=x, name='visual_classification_model')\n",
        "v_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FIiMzLVU2Cv",
        "outputId": "e26222b2-00a4-42e6-c2ed-b09172163731"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"visual_classification_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " v_input_layer (InputLayer)  [(None, 50, 20)]          0         \n",
            "                                                                 \n",
            " v_mask_layer (Masking)      (None, 50, 20)            0         \n",
            "                                                                 \n",
            " v_lstm_layer_1 (LSTM)       (None, 256)               283648    \n",
            "                                                                 \n",
            " v_dense_layer (Dense)       (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 284,162\n",
            "Trainable params: 284,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "hxVgRi_IWmqA"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_history = v_model.fit(train_visual_binary_ds, validation_data=valid_visual_binary_ds, \n",
        "            epochs=50, callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN5TRjBgXXJy",
        "outputId": "92181b62-a226-4e7a-b011-6f1684ec1a4f"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "21/21 [==============================] - 13s 382ms/step - loss: 0.6852 - accuracy: 0.5592 - val_loss: 0.6613 - val_accuracy: 0.5895\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 6s 290ms/step - loss: 0.6630 - accuracy: 0.5841 - val_loss: 0.6575 - val_accuracy: 0.5895\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 6s 291ms/step - loss: 0.6621 - accuracy: 0.6114 - val_loss: 0.6563 - val_accuracy: 0.5983\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 6s 282ms/step - loss: 0.6468 - accuracy: 0.6293 - val_loss: 0.6634 - val_accuracy: 0.5983\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 6s 289ms/step - loss: 0.6544 - accuracy: 0.6090 - val_loss: 0.6557 - val_accuracy: 0.5983\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 6s 291ms/step - loss: 0.6495 - accuracy: 0.6137 - val_loss: 0.6524 - val_accuracy: 0.5895\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 7s 342ms/step - loss: 0.6502 - accuracy: 0.6036 - val_loss: 0.6514 - val_accuracy: 0.5852\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 6s 290ms/step - loss: 0.6380 - accuracy: 0.6293 - val_loss: 0.6527 - val_accuracy: 0.5852\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 6s 292ms/step - loss: 0.6368 - accuracy: 0.6332 - val_loss: 0.6718 - val_accuracy: 0.5808\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 6s 293ms/step - loss: 0.6380 - accuracy: 0.6386 - val_loss: 0.6591 - val_accuracy: 0.5852\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 6s 285ms/step - loss: 0.6424 - accuracy: 0.6051 - val_loss: 0.6564 - val_accuracy: 0.5721\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 6s 285ms/step - loss: 0.6409 - accuracy: 0.6207 - val_loss: 0.6588 - val_accuracy: 0.5808\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 6s 277ms/step - loss: 0.6346 - accuracy: 0.6246 - val_loss: 0.6544 - val_accuracy: 0.5939\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 6s 286ms/step - loss: 0.6255 - accuracy: 0.6441 - val_loss: 0.6628 - val_accuracy: 0.6026\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 6s 278ms/step - loss: 0.6323 - accuracy: 0.6293 - val_loss: 0.6638 - val_accuracy: 0.5895\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 6s 307ms/step - loss: 0.6302 - accuracy: 0.6441 - val_loss: 0.6800 - val_accuracy: 0.5808\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 6s 293ms/step - loss: 0.6625 - accuracy: 0.6269 - val_loss: 0.6740 - val_accuracy: 0.5895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v_model.evaluate(test_visual_binary_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCiDxPijX1dh",
        "outputId": "6410602a-d428-429f-dfd6-66409eb453d0"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 1s 93ms/step - loss: 0.7315 - accuracy: 0.4927\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7314687371253967, 0.4927113652229309]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################\n",
        "##### Classification Model on visual Data with Attention #####\n",
        "##############################################################\n",
        "\n",
        "v_seq_len = 50\n",
        "v_latent_dim = 20\n",
        "\n",
        "v_input_shape = (v_seq_len, v_latent_dim)\n",
        "v_mask_value = np.zeros(shape=(v_latent_dim,), dtype=np.float32)\n",
        "\n",
        "v_input = Input(shape=v_input_shape, name='v_input_layer')\n",
        "v_mask_lyr = Masking(mask_value=v_mask_value, name='v_mask_layer')\n",
        "v_lstm_lyr = LSTM(256, return_sequences=True, dropout=0.4, name='v_lstm_layer_1')\n",
        "v_att_lyr = AttentionLayer()\n",
        "v_dense_lyr_1 = Dense(32, activation='relu',  name='v_dense_layer_1')\n",
        "v_dense_lyr_2 = Dense(2, activation='softmax', name='v_dense_layer_2')\n",
        "\n",
        "x = v_mask_lyr(v_input)\n",
        "x = v_lstm_lyr(x)\n",
        "att_we, att_op = v_att_lyr(x)\n",
        "op_1 = v_dense_lyr_1(att_op)\n",
        "op_2 = v_dense_lyr_2(op_1)\n",
        "\n",
        "v_model1 = Model(inputs=v_input, outputs=op_2, name='visual_classification_model_with_attention')\n",
        "v_model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHVNXCgpY5an",
        "outputId": "a88d5f8b-51e6-49c9-fedd-346a66bb66cd"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"visual_classification_model_with_attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " v_input_layer (InputLayer)  [(None, 50, 20)]          0         \n",
            "                                                                 \n",
            " v_mask_layer (Masking)      (None, 50, 20)            0         \n",
            "                                                                 \n",
            " v_lstm_layer_1 (LSTM)       (None, 50, 256)           283648    \n",
            "                                                                 \n",
            " attention_layer_1 (Attentio  ((None, 50, 1),          306       \n",
            " nLayer)                      (None, 256))                       \n",
            "                                                                 \n",
            " v_dense_layer_1 (Dense)     (None, 32)                8224      \n",
            "                                                                 \n",
            " v_dense_layer_2 (Dense)     (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 292,244\n",
            "Trainable params: 292,244\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v_model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
        "v_history1 = v_model1.fit(train_visual_binary_ds, validation_data=valid_visual_binary_ds, \n",
        "            epochs=50, callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv_pMrBQZe4g",
        "outputId": "16848afe-ab4b-4a32-cfa3-5222c698a13d"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "21/21 [==============================] - 13s 414ms/step - loss: 0.6924 - accuracy: 0.5779 - val_loss: 0.6793 - val_accuracy: 0.5983\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 6s 303ms/step - loss: 0.6802 - accuracy: 0.5935 - val_loss: 0.6709 - val_accuracy: 0.6157\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 6s 305ms/step - loss: 0.6687 - accuracy: 0.5958 - val_loss: 0.6731 - val_accuracy: 0.6026\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 6s 305ms/step - loss: 0.6584 - accuracy: 0.6184 - val_loss: 0.6625 - val_accuracy: 0.5808\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 6s 304ms/step - loss: 0.6652 - accuracy: 0.6114 - val_loss: 0.6612 - val_accuracy: 0.5895\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 6s 304ms/step - loss: 0.6475 - accuracy: 0.6223 - val_loss: 0.6626 - val_accuracy: 0.5808\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 6s 302ms/step - loss: 0.6577 - accuracy: 0.6215 - val_loss: 0.6705 - val_accuracy: 0.5895\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 6s 308ms/step - loss: 0.6559 - accuracy: 0.6083 - val_loss: 0.6619 - val_accuracy: 0.5852\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 6s 298ms/step - loss: 0.6464 - accuracy: 0.6199 - val_loss: 0.6727 - val_accuracy: 0.5895\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 6s 305ms/step - loss: 0.6488 - accuracy: 0.6145 - val_loss: 0.6540 - val_accuracy: 0.5852\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 6s 303ms/step - loss: 0.6455 - accuracy: 0.6160 - val_loss: 0.6538 - val_accuracy: 0.5983\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 6s 303ms/step - loss: 0.6395 - accuracy: 0.6207 - val_loss: 0.6572 - val_accuracy: 0.6026\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 6s 301ms/step - loss: 0.6378 - accuracy: 0.6293 - val_loss: 0.6759 - val_accuracy: 0.6026\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 6s 298ms/step - loss: 0.6410 - accuracy: 0.6223 - val_loss: 0.6538 - val_accuracy: 0.5852\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 6s 303ms/step - loss: 0.6324 - accuracy: 0.6262 - val_loss: 0.6593 - val_accuracy: 0.5852\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 6s 301ms/step - loss: 0.6393 - accuracy: 0.6231 - val_loss: 0.6564 - val_accuracy: 0.5895\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 6s 303ms/step - loss: 0.6450 - accuracy: 0.6215 - val_loss: 0.6647 - val_accuracy: 0.5808\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 6s 302ms/step - loss: 0.6304 - accuracy: 0.6394 - val_loss: 0.6744 - val_accuracy: 0.5764\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 6s 298ms/step - loss: 0.6359 - accuracy: 0.6262 - val_loss: 0.6691 - val_accuracy: 0.5852\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 6s 299ms/step - loss: 0.6327 - accuracy: 0.6386 - val_loss: 0.6679 - val_accuracy: 0.5852\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 6s 299ms/step - loss: 0.6295 - accuracy: 0.6332 - val_loss: 0.6685 - val_accuracy: 0.5808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v_model1.evaluate(test_visual_binary_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZiGfmqwZxK_",
        "outputId": "a5c015e4-25fd-4a19-889b-f8035188f96b"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 1s 93ms/step - loss: 0.6955 - accuracy: 0.5219\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6954590082168579, 0.5218659043312073]"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data_df['v_model1']= v_model1.predict(data_valid['vision'])[:,1] >= 0.5\n",
        "valid_data_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_-5HtJz0xUNl",
        "outputId": "fc90daca-e14c-418c-d49f-d29e31b3eeb2"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                f_name          s_time          e_time  true_labels  t_model  \\\n",
              "0    b'WKA5OygbEKI_20'  b'131.7929705'  b'133.6886621'         True     True   \n",
              "1    b'WKA5OygbEKI_21'  b'133.6886621'   b'138.976644'         True    False   \n",
              "2    b'WKA5OygbEKI_22'   b'170.544898'   b'172.729932'         True     True   \n",
              "3     b'WKA5OygbEKI_1'  b'4.432426304'  b'8.852380952'         True     True   \n",
              "4     b'WKA5OygbEKI_3'  b'45.95804989'  b'49.69954649'         True     True   \n",
              "..                 ...             ...             ...          ...      ...   \n",
              "224   b'c5xsKMxpXnc_4'  b'133.2097506'  b'135.8836735'         True     True   \n",
              "225   b'c5xsKMxpXnc_7'  b'149.3829932'  b'152.4360544'        False    False   \n",
              "226   b'c5xsKMxpXnc_6'  b'146.7290249'  b'149.3829932'        False    False   \n",
              "227   b'c5xsKMxpXnc_9'  b'156.6764172'  b'159.0609977'        False    False   \n",
              "228   b'c5xsKMxpXnc_8'  b'154.1122449'  b'156.6764172'        False    False   \n",
              "\n",
              "     v_model1  \n",
              "0        True  \n",
              "1        True  \n",
              "2        True  \n",
              "3        True  \n",
              "4        True  \n",
              "..        ...  \n",
              "224      True  \n",
              "225      True  \n",
              "226      True  \n",
              "227      True  \n",
              "228      True  \n",
              "\n",
              "[229 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b7bf314-3304-4758-b3fc-b7e80d95d71b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_name</th>\n",
              "      <th>s_time</th>\n",
              "      <th>e_time</th>\n",
              "      <th>true_labels</th>\n",
              "      <th>t_model</th>\n",
              "      <th>v_model1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b'WKA5OygbEKI_20'</td>\n",
              "      <td>b'131.7929705'</td>\n",
              "      <td>b'133.6886621'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b'WKA5OygbEKI_21'</td>\n",
              "      <td>b'133.6886621'</td>\n",
              "      <td>b'138.976644'</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b'WKA5OygbEKI_22'</td>\n",
              "      <td>b'170.544898'</td>\n",
              "      <td>b'172.729932'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b'WKA5OygbEKI_1'</td>\n",
              "      <td>b'4.432426304'</td>\n",
              "      <td>b'8.852380952'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b'WKA5OygbEKI_3'</td>\n",
              "      <td>b'45.95804989'</td>\n",
              "      <td>b'49.69954649'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>b'c5xsKMxpXnc_4'</td>\n",
              "      <td>b'133.2097506'</td>\n",
              "      <td>b'135.8836735'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>b'c5xsKMxpXnc_7'</td>\n",
              "      <td>b'149.3829932'</td>\n",
              "      <td>b'152.4360544'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>b'c5xsKMxpXnc_6'</td>\n",
              "      <td>b'146.7290249'</td>\n",
              "      <td>b'149.3829932'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>b'c5xsKMxpXnc_9'</td>\n",
              "      <td>b'156.6764172'</td>\n",
              "      <td>b'159.0609977'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>b'c5xsKMxpXnc_8'</td>\n",
              "      <td>b'154.1122449'</td>\n",
              "      <td>b'156.6764172'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>229 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b7bf314-3304-4758-b3fc-b7e80d95d71b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b7bf314-3304-4758-b3fc-b7e80d95d71b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b7bf314-3304-4758-b3fc-b7e80d95d71b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(valid_data_df.true_labels == valid_data_df.v_model1) / valid_data_df.v_model1.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX8Kd498xnIs",
        "outputId": "260841b1-da8a-47dd-da2b-4a2f2822f2fa"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5982532751091703"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis of Audio Data for Classification"
      ],
      "metadata": {
        "id": "BDhq2OW5OEeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train['audio'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bkcxhNNOoZ7",
        "outputId": "cd8b8508-5370-48ab-e63d-c04179fef723"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1284, 50, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing the data for training\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "buffer_size = 64\n",
        "batch_size = 64\n",
        "\n",
        "#############################################\n",
        "##### Dataset for Binary Classification #####\n",
        "#############################################\n",
        "\n",
        "train_audio_binary_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    data_train['audio'], \n",
        "                    data_train['labels']\n",
        "                )\n",
        "            ).map(lambda x,y: (x,[1, 0]) if y < 0 else (x,[0,1])).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "valid_audio_binary_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    data_valid['audio'],\n",
        "                    data_valid['labels']\n",
        "                )\n",
        "            ).map(lambda x,y: (x,[1, 0]) if y < 0 else (x,[0,1])).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "test_audio_binary_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    data_test['audio'],\n",
        "                    data_test['labels']\n",
        "                )\n",
        "            ).map(lambda x,y: (x,[1, 0]) if y < 0 else (x,[0,1])).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "\n",
        "#################################################\n",
        "##### Dataset for Multiclass Classification #####\n",
        "#################################################\n",
        "\n",
        "def convert_one_hot(x, y):\n",
        "  y = tf.squeeze(y)\n",
        "  return (x, tf.one_hot(tf.cast(tf.floor(y+3), tf.int64), 7))\n",
        "\n",
        "train_audio_multi_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    data_train['audio'], \n",
        "                    data_train['labels']\n",
        "                )\n",
        "            ).map(convert_one_hot).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "valid_audio_multi_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    data_valid['audio'],\n",
        "                    data_valid['labels']\n",
        "                )\n",
        "            ).map(convert_one_hot).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "test_audio_multi_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    data_test['audio'],\n",
        "                    data_test['labels']\n",
        "                )\n",
        "            ).map(convert_one_hot).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "TpkUwEgpCNsU"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################\n",
        "##### Classification Model on visual Data   #####\n",
        "#################################################\n",
        "\n",
        "a_seq_len = 50\n",
        "a_latent_dim = 5\n",
        "\n",
        "a_input_shape = (a_seq_len, a_latent_dim)\n",
        "a_mask_value = np.zeros(shape=(a_latent_dim,), dtype=np.float32)\n",
        "\n",
        "a_input = Input(shape=a_input_shape, name='a_input_layer')\n",
        "a_mask_lyr = Masking(mask_value=a_mask_value, name='a_mask_layer')\n",
        "a_lstm_lyr = LSTM(256, return_sequences=False, dropout=0.4, name='a_lstm_layer_1')\n",
        "a_dense_lyr = Dense(2, activation='softmax', name='a_dense_layer')\n",
        "\n",
        "\n",
        "x = a_mask_lyr(a_input)\n",
        "x = a_lstm_lyr(x)\n",
        "x = a_dense_lyr(x)\n",
        "\n",
        "a_model = Model(inputs=a_input, outputs=x, name='audio_classification_model')\n",
        "a_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93Y32H6xDXT8",
        "outputId": "ecf113b8-aab9-42c2-f326-e5e6947e7259"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"audio_classification_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " a_input_layer (InputLayer)  [(None, 50, 5)]           0         \n",
            "                                                                 \n",
            " a_mask_layer (Masking)      (None, 50, 5)             0         \n",
            "                                                                 \n",
            " a_lstm_layer_1 (LSTM)       (None, 256)               268288    \n",
            "                                                                 \n",
            " a_dense_layer (Dense)       (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 268,802\n",
            "Trainable params: 268,802\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
        "a_history = a_model.fit(train_audio_binary_ds, validation_data=valid_audio_binary_ds, \n",
        "            epochs=500, callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJXA6q69D9tf",
        "outputId": "e0dad593-8384-4f94-9edc-24f308d7ac0e"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "21/21 [==============================] - 12s 361ms/step - loss: 0.6881 - accuracy: 0.5530 - val_loss: 0.6808 - val_accuracy: 0.6070\n",
            "Epoch 2/500\n",
            "21/21 [==============================] - 6s 279ms/step - loss: 0.6860 - accuracy: 0.5646 - val_loss: 0.6713 - val_accuracy: 0.6026\n",
            "Epoch 3/500\n",
            "21/21 [==============================] - 6s 281ms/step - loss: 0.6767 - accuracy: 0.5864 - val_loss: 0.6782 - val_accuracy: 0.5852\n",
            "Epoch 4/500\n",
            "21/21 [==============================] - 6s 280ms/step - loss: 0.6784 - accuracy: 0.5872 - val_loss: 0.6682 - val_accuracy: 0.5939\n",
            "Epoch 5/500\n",
            "21/21 [==============================] - 6s 273ms/step - loss: 0.6746 - accuracy: 0.6020 - val_loss: 0.6764 - val_accuracy: 0.6026\n",
            "Epoch 6/500\n",
            "21/21 [==============================] - 6s 291ms/step - loss: 0.6765 - accuracy: 0.5888 - val_loss: 0.6676 - val_accuracy: 0.6070\n",
            "Epoch 7/500\n",
            "21/21 [==============================] - 6s 285ms/step - loss: 0.6701 - accuracy: 0.6044 - val_loss: 0.6687 - val_accuracy: 0.5983\n",
            "Epoch 8/500\n",
            "21/21 [==============================] - 7s 358ms/step - loss: 0.6705 - accuracy: 0.5966 - val_loss: 0.6703 - val_accuracy: 0.6114\n",
            "Epoch 9/500\n",
            "21/21 [==============================] - 6s 280ms/step - loss: 0.6765 - accuracy: 0.5872 - val_loss: 0.6723 - val_accuracy: 0.6026\n",
            "Epoch 10/500\n",
            "21/21 [==============================] - 6s 278ms/step - loss: 0.6718 - accuracy: 0.5911 - val_loss: 0.6649 - val_accuracy: 0.5895\n",
            "Epoch 11/500\n",
            "21/21 [==============================] - 6s 279ms/step - loss: 0.6687 - accuracy: 0.6044 - val_loss: 0.6725 - val_accuracy: 0.6201\n",
            "Epoch 12/500\n",
            "21/21 [==============================] - 7s 340ms/step - loss: 0.6701 - accuracy: 0.5903 - val_loss: 0.6640 - val_accuracy: 0.6070\n",
            "Epoch 13/500\n",
            "21/21 [==============================] - 6s 284ms/step - loss: 0.6671 - accuracy: 0.6051 - val_loss: 0.6707 - val_accuracy: 0.6201\n",
            "Epoch 14/500\n",
            "21/21 [==============================] - 6s 282ms/step - loss: 0.6709 - accuracy: 0.5981 - val_loss: 0.6624 - val_accuracy: 0.6114\n",
            "Epoch 15/500\n",
            "21/21 [==============================] - 6s 280ms/step - loss: 0.6655 - accuracy: 0.6059 - val_loss: 0.6631 - val_accuracy: 0.6114\n",
            "Epoch 16/500\n",
            "21/21 [==============================] - 6s 281ms/step - loss: 0.6675 - accuracy: 0.5935 - val_loss: 0.6692 - val_accuracy: 0.6070\n",
            "Epoch 17/500\n",
            "21/21 [==============================] - 6s 279ms/step - loss: 0.6724 - accuracy: 0.6106 - val_loss: 0.6613 - val_accuracy: 0.6114\n",
            "Epoch 18/500\n",
            "21/21 [==============================] - 6s 280ms/step - loss: 0.6625 - accuracy: 0.6114 - val_loss: 0.6663 - val_accuracy: 0.6026\n",
            "Epoch 19/500\n",
            "21/21 [==============================] - 6s 282ms/step - loss: 0.6679 - accuracy: 0.6036 - val_loss: 0.6655 - val_accuracy: 0.6201\n",
            "Epoch 20/500\n",
            "21/21 [==============================] - 6s 280ms/step - loss: 0.6646 - accuracy: 0.6098 - val_loss: 0.6641 - val_accuracy: 0.6245\n",
            "Epoch 21/500\n",
            "21/21 [==============================] - 6s 280ms/step - loss: 0.6679 - accuracy: 0.6020 - val_loss: 0.6669 - val_accuracy: 0.6288\n",
            "Epoch 22/500\n",
            "21/21 [==============================] - 6s 276ms/step - loss: 0.6717 - accuracy: 0.5880 - val_loss: 0.6592 - val_accuracy: 0.6157\n",
            "Epoch 23/500\n",
            "21/21 [==============================] - 6s 277ms/step - loss: 0.6665 - accuracy: 0.6044 - val_loss: 0.6706 - val_accuracy: 0.5852\n",
            "Epoch 24/500\n",
            "21/21 [==============================] - 6s 277ms/step - loss: 0.6678 - accuracy: 0.6012 - val_loss: 0.6584 - val_accuracy: 0.6288\n",
            "Epoch 25/500\n",
            "21/21 [==============================] - 6s 282ms/step - loss: 0.6608 - accuracy: 0.6176 - val_loss: 0.6645 - val_accuracy: 0.6070\n",
            "Epoch 26/500\n",
            "21/21 [==============================] - 6s 283ms/step - loss: 0.6677 - accuracy: 0.5966 - val_loss: 0.6622 - val_accuracy: 0.6201\n",
            "Epoch 27/500\n",
            "21/21 [==============================] - 6s 280ms/step - loss: 0.6631 - accuracy: 0.6067 - val_loss: 0.6617 - val_accuracy: 0.6114\n",
            "Epoch 28/500\n",
            "21/21 [==============================] - 6s 275ms/step - loss: 0.6655 - accuracy: 0.6083 - val_loss: 0.6627 - val_accuracy: 0.6201\n",
            "Epoch 29/500\n",
            "21/21 [==============================] - 6s 284ms/step - loss: 0.6540 - accuracy: 0.6184 - val_loss: 0.6658 - val_accuracy: 0.6332\n",
            "Epoch 30/500\n",
            "21/21 [==============================] - 6s 273ms/step - loss: 0.6581 - accuracy: 0.6192 - val_loss: 0.6619 - val_accuracy: 0.6157\n",
            "Epoch 31/500\n",
            "21/21 [==============================] - 6s 280ms/step - loss: 0.6669 - accuracy: 0.6012 - val_loss: 0.6600 - val_accuracy: 0.6376\n",
            "Epoch 32/500\n",
            "21/21 [==============================] - 6s 284ms/step - loss: 0.6595 - accuracy: 0.6223 - val_loss: 0.6598 - val_accuracy: 0.6332\n",
            "Epoch 33/500\n",
            "21/21 [==============================] - 6s 279ms/step - loss: 0.6629 - accuracy: 0.6129 - val_loss: 0.6575 - val_accuracy: 0.6463\n",
            "Epoch 34/500\n",
            "21/21 [==============================] - 6s 287ms/step - loss: 0.6639 - accuracy: 0.6051 - val_loss: 0.6595 - val_accuracy: 0.6201\n",
            "Epoch 35/500\n",
            "21/21 [==============================] - 6s 279ms/step - loss: 0.6608 - accuracy: 0.6160 - val_loss: 0.6630 - val_accuracy: 0.6070\n",
            "Epoch 36/500\n",
            "21/21 [==============================] - 6s 279ms/step - loss: 0.6636 - accuracy: 0.6137 - val_loss: 0.6597 - val_accuracy: 0.6288\n",
            "Epoch 37/500\n",
            "21/21 [==============================] - 6s 282ms/step - loss: 0.6653 - accuracy: 0.6036 - val_loss: 0.6566 - val_accuracy: 0.6114\n",
            "Epoch 38/500\n",
            "21/21 [==============================] - 6s 274ms/step - loss: 0.6585 - accuracy: 0.6223 - val_loss: 0.6651 - val_accuracy: 0.6201\n",
            "Epoch 39/500\n",
            "21/21 [==============================] - 6s 273ms/step - loss: 0.6581 - accuracy: 0.6106 - val_loss: 0.6588 - val_accuracy: 0.6245\n",
            "Epoch 40/500\n",
            "21/21 [==============================] - 6s 275ms/step - loss: 0.6582 - accuracy: 0.6168 - val_loss: 0.6576 - val_accuracy: 0.6419\n",
            "Epoch 41/500\n",
            "21/21 [==============================] - 6s 274ms/step - loss: 0.6591 - accuracy: 0.6168 - val_loss: 0.6616 - val_accuracy: 0.6288\n",
            "Epoch 42/500\n",
            "21/21 [==============================] - 6s 274ms/step - loss: 0.6703 - accuracy: 0.5935 - val_loss: 0.6541 - val_accuracy: 0.6419\n",
            "Epoch 43/500\n",
            "21/21 [==============================] - 7s 331ms/step - loss: 0.6610 - accuracy: 0.6176 - val_loss: 0.6542 - val_accuracy: 0.6376\n",
            "Epoch 44/500\n",
            "21/21 [==============================] - 6s 276ms/step - loss: 0.6575 - accuracy: 0.6207 - val_loss: 0.6574 - val_accuracy: 0.6288\n",
            "Epoch 45/500\n",
            "21/21 [==============================] - 6s 276ms/step - loss: 0.6644 - accuracy: 0.6044 - val_loss: 0.6544 - val_accuracy: 0.6245\n",
            "Epoch 46/500\n",
            "21/21 [==============================] - 6s 277ms/step - loss: 0.6592 - accuracy: 0.6083 - val_loss: 0.6629 - val_accuracy: 0.5983\n",
            "Epoch 47/500\n",
            "21/21 [==============================] - 6s 277ms/step - loss: 0.6581 - accuracy: 0.6215 - val_loss: 0.6567 - val_accuracy: 0.6201\n",
            "Epoch 48/500\n",
            "21/21 [==============================] - 6s 275ms/step - loss: 0.6576 - accuracy: 0.5958 - val_loss: 0.6565 - val_accuracy: 0.6419\n",
            "Epoch 49/500\n",
            "21/21 [==============================] - 6s 278ms/step - loss: 0.6607 - accuracy: 0.6238 - val_loss: 0.6586 - val_accuracy: 0.6157\n",
            "Epoch 50/500\n",
            "21/21 [==============================] - 6s 280ms/step - loss: 0.6606 - accuracy: 0.6246 - val_loss: 0.6639 - val_accuracy: 0.6114\n",
            "Epoch 51/500\n",
            "21/21 [==============================] - 6s 283ms/step - loss: 0.6588 - accuracy: 0.6207 - val_loss: 0.6528 - val_accuracy: 0.6288\n",
            "Epoch 52/500\n",
            "21/21 [==============================] - 6s 288ms/step - loss: 0.6584 - accuracy: 0.6160 - val_loss: 0.6542 - val_accuracy: 0.6288\n",
            "Epoch 53/500\n",
            "21/21 [==============================] - 6s 288ms/step - loss: 0.6541 - accuracy: 0.6215 - val_loss: 0.6572 - val_accuracy: 0.6288\n",
            "Epoch 54/500\n",
            "21/21 [==============================] - 6s 286ms/step - loss: 0.6514 - accuracy: 0.6238 - val_loss: 0.6562 - val_accuracy: 0.6419\n",
            "Epoch 55/500\n",
            "21/21 [==============================] - 6s 291ms/step - loss: 0.6550 - accuracy: 0.6137 - val_loss: 0.6548 - val_accuracy: 0.6070\n",
            "Epoch 56/500\n",
            "21/21 [==============================] - 6s 292ms/step - loss: 0.6612 - accuracy: 0.6012 - val_loss: 0.6549 - val_accuracy: 0.6114\n",
            "Epoch 57/500\n",
            "21/21 [==============================] - 6s 284ms/step - loss: 0.6557 - accuracy: 0.6223 - val_loss: 0.6578 - val_accuracy: 0.6245\n",
            "Epoch 58/500\n",
            "21/21 [==============================] - 6s 283ms/step - loss: 0.6562 - accuracy: 0.6192 - val_loss: 0.6540 - val_accuracy: 0.6201\n",
            "Epoch 59/500\n",
            "21/21 [==============================] - 6s 283ms/step - loss: 0.6545 - accuracy: 0.6277 - val_loss: 0.6594 - val_accuracy: 0.6201\n",
            "Epoch 60/500\n",
            "21/21 [==============================] - 6s 290ms/step - loss: 0.6520 - accuracy: 0.6254 - val_loss: 0.6628 - val_accuracy: 0.6201\n",
            "Epoch 61/500\n",
            "21/21 [==============================] - 6s 286ms/step - loss: 0.6506 - accuracy: 0.6192 - val_loss: 0.6582 - val_accuracy: 0.6376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_model.evaluate(test_audio_binary_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG3aOEKOKNwE",
        "outputId": "c177af0c-618d-41b1-b45d-6e829126b6d3"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6981 - accuracy: 0.5423\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6980618238449097, 0.5422740578651428]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################\n",
        "##### Classification Model on visual Data with Attention #####\n",
        "##############################################################\n",
        "\n",
        "a_seq_len = 50\n",
        "a_latent_dim = 5\n",
        "\n",
        "a_input_shape = (a_seq_len, a_latent_dim)\n",
        "a_mask_value = np.zeros(shape=(a_latent_dim,), dtype=np.float32)\n",
        "\n",
        "a_input = Input(shape=a_input_shape, name='a_input_layer')\n",
        "a_mask_lyr = Masking(mask_value=a_mask_value, name='a_mask_layer')\n",
        "a_lstm_lyr = LSTM(256, return_sequences=True, dropout=0.4, name='a_lstm_layer_1')\n",
        "a_att_lyr = AttentionLayer()\n",
        "a_dense_lyr_1 = Dense(32, activation='relu',  name='a_dense_layer_1')\n",
        "a_dense_lyr_2 = Dense(2, activation='softmax', name='a_dense_layer_2')\n",
        "\n",
        "x = a_mask_lyr(a_input)\n",
        "x = a_lstm_lyr(x)\n",
        "att_we, att_op = a_att_lyr(x)\n",
        "op_1 = a_dense_lyr_1(att_op)\n",
        "op_2 = a_dense_lyr_2(op_1)\n",
        "\n",
        "a_model1 = Model(inputs=a_input, outputs=op_2, name='audio_classification_model_with_attention')\n",
        "a_model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOqagNNnD9qf",
        "outputId": "582ea33e-bb52-475c-d3c6-9f3b904254cb"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"audio_classification_model_with_attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " a_input_layer (InputLayer)  [(None, 50, 5)]           0         \n",
            "                                                                 \n",
            " a_mask_layer (Masking)      (None, 50, 5)             0         \n",
            "                                                                 \n",
            " a_lstm_layer_1 (LSTM)       (None, 50, 256)           268288    \n",
            "                                                                 \n",
            " attention_layer_2 (Attentio  ((None, 50, 1),          306       \n",
            " nLayer)                      (None, 256))                       \n",
            "                                                                 \n",
            " a_dense_layer_1 (Dense)     (None, 32)                8224      \n",
            "                                                                 \n",
            " a_dense_layer_2 (Dense)     (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 276,884\n",
            "Trainable params: 276,884\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
        "a_history1 = a_model1.fit(train_audio_binary_ds, validation_data=valid_audio_binary_ds, \n",
        "            epochs=50, callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGFcPU73D9no",
        "outputId": "aa48f9a1-ce50-49c3-9e65-1c496d295d52"
      },
      "execution_count": 115,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "21/21 [==============================] - 13s 384ms/step - loss: 0.6925 - accuracy: 0.5615 - val_loss: 0.6874 - val_accuracy: 0.5677\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 6s 304ms/step - loss: 0.6864 - accuracy: 0.5794 - val_loss: 0.6847 - val_accuracy: 0.5895\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 6s 297ms/step - loss: 0.6843 - accuracy: 0.5935 - val_loss: 0.6800 - val_accuracy: 0.6157\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 6s 296ms/step - loss: 0.6803 - accuracy: 0.5857 - val_loss: 0.6795 - val_accuracy: 0.6070\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 6s 301ms/step - loss: 0.6765 - accuracy: 0.5888 - val_loss: 0.6882 - val_accuracy: 0.5721\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 6s 285ms/step - loss: 0.6755 - accuracy: 0.5997 - val_loss: 0.6771 - val_accuracy: 0.5939\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 6s 281ms/step - loss: 0.6715 - accuracy: 0.5958 - val_loss: 0.6779 - val_accuracy: 0.5939\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 6s 295ms/step - loss: 0.6731 - accuracy: 0.5974 - val_loss: 0.6761 - val_accuracy: 0.5983\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 6s 290ms/step - loss: 0.6699 - accuracy: 0.6012 - val_loss: 0.6805 - val_accuracy: 0.5764\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 6s 289ms/step - loss: 0.6740 - accuracy: 0.5997 - val_loss: 0.6744 - val_accuracy: 0.5895\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 6s 286ms/step - loss: 0.6674 - accuracy: 0.6083 - val_loss: 0.6774 - val_accuracy: 0.5852\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 6s 286ms/step - loss: 0.6640 - accuracy: 0.6145 - val_loss: 0.6839 - val_accuracy: 0.5895\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 6s 287ms/step - loss: 0.6719 - accuracy: 0.6044 - val_loss: 0.6674 - val_accuracy: 0.6026\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 6s 285ms/step - loss: 0.6667 - accuracy: 0.6098 - val_loss: 0.6742 - val_accuracy: 0.5852\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 6s 281ms/step - loss: 0.6695 - accuracy: 0.6075 - val_loss: 0.6741 - val_accuracy: 0.5764\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 6s 286ms/step - loss: 0.6683 - accuracy: 0.6005 - val_loss: 0.6692 - val_accuracy: 0.6070\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 6s 285ms/step - loss: 0.6686 - accuracy: 0.5927 - val_loss: 0.6659 - val_accuracy: 0.6114\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 6s 296ms/step - loss: 0.6663 - accuracy: 0.6051 - val_loss: 0.6715 - val_accuracy: 0.5939\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 6s 285ms/step - loss: 0.6724 - accuracy: 0.5989 - val_loss: 0.6681 - val_accuracy: 0.6070\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 6s 293ms/step - loss: 0.6625 - accuracy: 0.6090 - val_loss: 0.6753 - val_accuracy: 0.5721\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 6s 293ms/step - loss: 0.6691 - accuracy: 0.6051 - val_loss: 0.6673 - val_accuracy: 0.5939\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 7s 318ms/step - loss: 0.6652 - accuracy: 0.6083 - val_loss: 0.6706 - val_accuracy: 0.5764\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 6s 294ms/step - loss: 0.6694 - accuracy: 0.5966 - val_loss: 0.6683 - val_accuracy: 0.6026\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 6s 306ms/step - loss: 0.6656 - accuracy: 0.6044 - val_loss: 0.6709 - val_accuracy: 0.5939\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 8s 372ms/step - loss: 0.6642 - accuracy: 0.6129 - val_loss: 0.6665 - val_accuracy: 0.6026\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 7s 315ms/step - loss: 0.6623 - accuracy: 0.6090 - val_loss: 0.6662 - val_accuracy: 0.6201\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 7s 339ms/step - loss: 0.6666 - accuracy: 0.6137 - val_loss: 0.6656 - val_accuracy: 0.6026\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 6s 309ms/step - loss: 0.6648 - accuracy: 0.6098 - val_loss: 0.6664 - val_accuracy: 0.6201\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 7s 315ms/step - loss: 0.6648 - accuracy: 0.6083 - val_loss: 0.6630 - val_accuracy: 0.6114\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 7s 317ms/step - loss: 0.6654 - accuracy: 0.6067 - val_loss: 0.6637 - val_accuracy: 0.6157\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 7s 315ms/step - loss: 0.6645 - accuracy: 0.6160 - val_loss: 0.6665 - val_accuracy: 0.6157\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 7s 311ms/step - loss: 0.6650 - accuracy: 0.5974 - val_loss: 0.6659 - val_accuracy: 0.6157\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 6s 306ms/step - loss: 0.6661 - accuracy: 0.6028 - val_loss: 0.6655 - val_accuracy: 0.6201\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 6s 301ms/step - loss: 0.6658 - accuracy: 0.6137 - val_loss: 0.6652 - val_accuracy: 0.6288\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 7s 321ms/step - loss: 0.6650 - accuracy: 0.6059 - val_loss: 0.6649 - val_accuracy: 0.5983\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 6s 302ms/step - loss: 0.6601 - accuracy: 0.6192 - val_loss: 0.6654 - val_accuracy: 0.6288\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 6s 304ms/step - loss: 0.6657 - accuracy: 0.6114 - val_loss: 0.6593 - val_accuracy: 0.6376\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 6s 294ms/step - loss: 0.6640 - accuracy: 0.6106 - val_loss: 0.6585 - val_accuracy: 0.6419\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 7s 344ms/step - loss: 0.6632 - accuracy: 0.6137 - val_loss: 0.6591 - val_accuracy: 0.6201\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 7s 319ms/step - loss: 0.6634 - accuracy: 0.6114 - val_loss: 0.6596 - val_accuracy: 0.6376\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 6s 297ms/step - loss: 0.6633 - accuracy: 0.6083 - val_loss: 0.6605 - val_accuracy: 0.6332\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 6s 289ms/step - loss: 0.6605 - accuracy: 0.6075 - val_loss: 0.6584 - val_accuracy: 0.6288\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 6s 289ms/step - loss: 0.6597 - accuracy: 0.6129 - val_loss: 0.6592 - val_accuracy: 0.6245\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 6s 298ms/step - loss: 0.6611 - accuracy: 0.6020 - val_loss: 0.6590 - val_accuracy: 0.6157\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 6s 295ms/step - loss: 0.6643 - accuracy: 0.6036 - val_loss: 0.6593 - val_accuracy: 0.6201\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 6s 297ms/step - loss: 0.6611 - accuracy: 0.6059 - val_loss: 0.6646 - val_accuracy: 0.6070\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 6s 293ms/step - loss: 0.6593 - accuracy: 0.6176 - val_loss: 0.6613 - val_accuracy: 0.6070\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 6s 292ms/step - loss: 0.6721 - accuracy: 0.5935 - val_loss: 0.6604 - val_accuracy: 0.6157\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 6s 289ms/step - loss: 0.6618 - accuracy: 0.6114 - val_loss: 0.6592 - val_accuracy: 0.6157\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 6s 301ms/step - loss: 0.6592 - accuracy: 0.6199 - val_loss: 0.6624 - val_accuracy: 0.5939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_model1.evaluate(test_audio_binary_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK_X6LAFD9kt",
        "outputId": "07c5d2a8-ca3f-4632-ae19-b024d738e060"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 1s 91ms/step - loss: 0.6919 - accuracy: 0.5598\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6918613910675049, 0.5597667694091797]"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data_df['a_model1']= a_model1.predict(data_valid['audio'])[:,1] >= 0.5\n",
        "valid_data_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vYuJprmZ2_Ok",
        "outputId": "24ec1ef9-aeac-4836-f484-b932a503a30e"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                f_name          s_time          e_time  true_labels  t_model  \\\n",
              "0    b'WKA5OygbEKI_20'  b'131.7929705'  b'133.6886621'         True     True   \n",
              "1    b'WKA5OygbEKI_21'  b'133.6886621'   b'138.976644'         True    False   \n",
              "2    b'WKA5OygbEKI_22'   b'170.544898'   b'172.729932'         True     True   \n",
              "3     b'WKA5OygbEKI_1'  b'4.432426304'  b'8.852380952'         True     True   \n",
              "4     b'WKA5OygbEKI_3'  b'45.95804989'  b'49.69954649'         True     True   \n",
              "..                 ...             ...             ...          ...      ...   \n",
              "224   b'c5xsKMxpXnc_4'  b'133.2097506'  b'135.8836735'         True     True   \n",
              "225   b'c5xsKMxpXnc_7'  b'149.3829932'  b'152.4360544'        False    False   \n",
              "226   b'c5xsKMxpXnc_6'  b'146.7290249'  b'149.3829932'        False    False   \n",
              "227   b'c5xsKMxpXnc_9'  b'156.6764172'  b'159.0609977'        False    False   \n",
              "228   b'c5xsKMxpXnc_8'  b'154.1122449'  b'156.6764172'        False    False   \n",
              "\n",
              "     v_model1  a_model1  \n",
              "0        True      True  \n",
              "1        True      True  \n",
              "2        True      True  \n",
              "3        True      True  \n",
              "4        True      True  \n",
              "..        ...       ...  \n",
              "224      True     False  \n",
              "225      True      True  \n",
              "226      True      True  \n",
              "227      True      True  \n",
              "228      True      True  \n",
              "\n",
              "[229 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d19e507-5c10-43aa-8431-64bfd7952826\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_name</th>\n",
              "      <th>s_time</th>\n",
              "      <th>e_time</th>\n",
              "      <th>true_labels</th>\n",
              "      <th>t_model</th>\n",
              "      <th>v_model1</th>\n",
              "      <th>a_model1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b'WKA5OygbEKI_20'</td>\n",
              "      <td>b'131.7929705'</td>\n",
              "      <td>b'133.6886621'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b'WKA5OygbEKI_21'</td>\n",
              "      <td>b'133.6886621'</td>\n",
              "      <td>b'138.976644'</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b'WKA5OygbEKI_22'</td>\n",
              "      <td>b'170.544898'</td>\n",
              "      <td>b'172.729932'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b'WKA5OygbEKI_1'</td>\n",
              "      <td>b'4.432426304'</td>\n",
              "      <td>b'8.852380952'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b'WKA5OygbEKI_3'</td>\n",
              "      <td>b'45.95804989'</td>\n",
              "      <td>b'49.69954649'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>b'c5xsKMxpXnc_4'</td>\n",
              "      <td>b'133.2097506'</td>\n",
              "      <td>b'135.8836735'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>b'c5xsKMxpXnc_7'</td>\n",
              "      <td>b'149.3829932'</td>\n",
              "      <td>b'152.4360544'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>b'c5xsKMxpXnc_6'</td>\n",
              "      <td>b'146.7290249'</td>\n",
              "      <td>b'149.3829932'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>b'c5xsKMxpXnc_9'</td>\n",
              "      <td>b'156.6764172'</td>\n",
              "      <td>b'159.0609977'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>b'c5xsKMxpXnc_8'</td>\n",
              "      <td>b'154.1122449'</td>\n",
              "      <td>b'156.6764172'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>229 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d19e507-5c10-43aa-8431-64bfd7952826')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3d19e507-5c10-43aa-8431-64bfd7952826 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3d19e507-5c10-43aa-8431-64bfd7952826');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### T + V"
      ],
      "metadata": {
        "id": "QiVuK8bTvbuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing the data for training\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "buffer_size = 64\n",
        "batch_size = 64\n",
        "\n",
        "###################################################################\n",
        "##### Dataset for Binary Classification Text and Visual Model #####\n",
        "###################################################################\n",
        "\n",
        "train_tv_binary_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    (data_train['text'],\n",
        "                    data_train['vision']), \n",
        "                    data_train['labels']\n",
        "                )\n",
        "            ).map(lambda x,y: (x,[1, 0]) if y < 0 else (x,[0,1])).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "valid_tv_binary_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    (data_valid['text'],\n",
        "                    data_valid['vision']),\n",
        "                    data_valid['labels']\n",
        "                )\n",
        "            ).map(lambda x,y: (x,[1, 0]) if y < 0 else (x,[0,1])).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "test_tv_binary_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    (data_test['text'],\n",
        "                    data_test['vision']),\n",
        "                    data_test['labels']\n",
        "                )\n",
        "            ).map(lambda x,y: (x,[1, 0]) if y < 0 else (x,[0,1])).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "Kn9bx8Rvj7Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in train_tv_binary_ds.take(1):\n",
        "  print(data)"
      ],
      "metadata": {
        "id": "UZkjpRssk76c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################\n",
        "#### Merging textual and visual analysis #####\n",
        "##############################################\n",
        "\n",
        "t_lstm_lyr.trainable = False\n",
        "t_att_lyr.trainable  = False\n",
        "t_dense_lyr_1.trainable = False\n",
        "\n",
        "v_lstm_lyr.trainable = False\n",
        "v_att_lyr.trainable  = False\n",
        "v_dense_lyr_1.trainable = False\n",
        "\n",
        "\n",
        "t_x = t_mask_lyr(t_input)\n",
        "t_x = t_lstm_lyr(t_x)\n",
        "t_att_we, t_att_op = t_att_lyr(t_x)\n",
        "t_op = t_dense_lyr_1(t_att_op)\n",
        "\n",
        "v_x = v_mask_lyr(v_input)\n",
        "v_x = v_lstm_lyr(v_x)\n",
        "v_att_we, v_att_op = v_att_lyr(v_x)\n",
        "v_op = v_dense_lyr_1(v_att_op)\n",
        "\n",
        "# x = tf.keras.layers.concatenate((t_att_op, v_att_op))\n",
        "# x = tf.keras.layers.concatenate((t_op, v_op))\n",
        "x  = tf.keras.layers.Lambda(lambda x: tf.math.multiply(x[0],x[1]))((t_op, v_op))\n",
        "\n",
        "tv_dense_1 = Dense(16, activation='softmax', name='text_visual_dense_layer_1')\n",
        "tv_dense = Dense(2, activation='softmax', name='text_visual_dense_layer')\n",
        "\n",
        "x = tv_dense_1(x)\n",
        "op = tv_dense(x)\n",
        "\n",
        "tv_model = Model(inputs=[t_input, v_input], outputs=op, name='Text_Visual_Model')\n",
        "tv_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiSEbtf_aq7I",
        "outputId": "a0480f1f-9929-4888-ef2f-03d708d21f08"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Text_Visual_Model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text_input_layer (InputLayer)  [(None, 50, 300)]    0           []                               \n",
            "                                                                                                  \n",
            " v_input_layer (InputLayer)     [(None, 50, 20)]     0           []                               \n",
            "                                                                                                  \n",
            " text_masking_layer (Masking)   (None, 50, 300)      0           ['text_input_layer[0][0]']       \n",
            "                                                                                                  \n",
            " v_mask_layer (Masking)         (None, 50, 20)       0           ['v_input_layer[0][0]']          \n",
            "                                                                                                  \n",
            " text_lstm_layer_1 (LSTM)       (None, 50, 256)      570368      ['text_masking_layer[8][0]']     \n",
            "                                                                                                  \n",
            " v_lstm_layer_1 (LSTM)          (None, 50, 256)      283648      ['v_mask_layer[8][0]']           \n",
            "                                                                                                  \n",
            " attention_layer_2 (AttentionLa  ((None, 50, 1),     306         ['text_lstm_layer_1[8][0]']      \n",
            " yer)                            (None, 256))                                                     \n",
            "                                                                                                  \n",
            " attention_layer_4 (AttentionLa  ((None, 50, 1),     306         ['v_lstm_layer_1[8][0]']         \n",
            " yer)                            (None, 256))                                                     \n",
            "                                                                                                  \n",
            " text_dense_layer_1 (Dense)     (None, 32)           8224        ['attention_layer_2[8][1]']      \n",
            "                                                                                                  \n",
            " v_dense_layer_1 (Dense)        (None, 32)           8224        ['attention_layer_4[8][1]']      \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 32)           0           ['text_dense_layer_1[8][0]',     \n",
            "                                                                  'v_dense_layer_1[8][0]']        \n",
            "                                                                                                  \n",
            " text_visual_dense_layer_1 (Den  (None, 16)          528         ['lambda_1[0][0]']               \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " text_visual_dense_layer (Dense  (None, 2)           34          ['text_visual_dense_layer_1[0][0]\n",
            " )                                                               ']                               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 871,638\n",
            "Trainable params: 562\n",
            "Non-trainable params: 871,076\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tv_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
        "tv_history1 = tv_model.fit(train_tv_binary_ds, validation_data=valid_tv_binary_ds, \n",
        "            epochs=500, callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvNXnIGBiK0G",
        "outputId": "2e3e7a50-93d2-40e0-f3f1-eba905310f43"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "21/21 [==============================] - 9s 430ms/step - loss: 0.6446 - accuracy: 0.5763 - val_loss: 0.6429 - val_accuracy: 0.6026\n",
            "Epoch 2/500\n",
            "21/21 [==============================] - 9s 439ms/step - loss: 0.6432 - accuracy: 0.5732 - val_loss: 0.6417 - val_accuracy: 0.6026\n",
            "Epoch 3/500\n",
            "21/21 [==============================] - 8s 380ms/step - loss: 0.6416 - accuracy: 0.5732 - val_loss: 0.6405 - val_accuracy: 0.6026\n",
            "Epoch 4/500\n",
            "21/21 [==============================] - 5s 247ms/step - loss: 0.6397 - accuracy: 0.5779 - val_loss: 0.6395 - val_accuracy: 0.6026\n",
            "Epoch 5/500\n",
            "21/21 [==============================] - 5s 255ms/step - loss: 0.6378 - accuracy: 0.5771 - val_loss: 0.6382 - val_accuracy: 0.6026\n",
            "Epoch 6/500\n",
            "21/21 [==============================] - 5s 245ms/step - loss: 0.6369 - accuracy: 0.5787 - val_loss: 0.6368 - val_accuracy: 0.6026\n",
            "Epoch 7/500\n",
            "21/21 [==============================] - 5s 251ms/step - loss: 0.6343 - accuracy: 0.5794 - val_loss: 0.6352 - val_accuracy: 0.6026\n",
            "Epoch 8/500\n",
            "21/21 [==============================] - 5s 251ms/step - loss: 0.6333 - accuracy: 0.5787 - val_loss: 0.6339 - val_accuracy: 0.6026\n",
            "Epoch 9/500\n",
            "21/21 [==============================] - 5s 252ms/step - loss: 0.6306 - accuracy: 0.5818 - val_loss: 0.6328 - val_accuracy: 0.6026\n",
            "Epoch 10/500\n",
            "21/21 [==============================] - 5s 228ms/step - loss: 0.6288 - accuracy: 0.5833 - val_loss: 0.6313 - val_accuracy: 0.5983\n",
            "Epoch 11/500\n",
            "21/21 [==============================] - 5s 238ms/step - loss: 0.6270 - accuracy: 0.5864 - val_loss: 0.6300 - val_accuracy: 0.6026\n",
            "Epoch 12/500\n",
            "21/21 [==============================] - 5s 229ms/step - loss: 0.6255 - accuracy: 0.5841 - val_loss: 0.6289 - val_accuracy: 0.6070\n",
            "Epoch 13/500\n",
            "21/21 [==============================] - 5s 234ms/step - loss: 0.6231 - accuracy: 0.5981 - val_loss: 0.6279 - val_accuracy: 0.6201\n",
            "Epoch 14/500\n",
            "21/21 [==============================] - 6s 292ms/step - loss: 0.6214 - accuracy: 0.6012 - val_loss: 0.6265 - val_accuracy: 0.6201\n",
            "Epoch 15/500\n",
            "21/21 [==============================] - 5s 236ms/step - loss: 0.6199 - accuracy: 0.6012 - val_loss: 0.6250 - val_accuracy: 0.6201\n",
            "Epoch 16/500\n",
            "21/21 [==============================] - 5s 236ms/step - loss: 0.6174 - accuracy: 0.6044 - val_loss: 0.6236 - val_accuracy: 0.6288\n",
            "Epoch 17/500\n",
            "21/21 [==============================] - 5s 259ms/step - loss: 0.6156 - accuracy: 0.6137 - val_loss: 0.6223 - val_accuracy: 0.6332\n",
            "Epoch 18/500\n",
            "21/21 [==============================] - 5s 240ms/step - loss: 0.6139 - accuracy: 0.6137 - val_loss: 0.6211 - val_accuracy: 0.6419\n",
            "Epoch 19/500\n",
            "21/21 [==============================] - 6s 291ms/step - loss: 0.6112 - accuracy: 0.6332 - val_loss: 0.6198 - val_accuracy: 0.6419\n",
            "Epoch 20/500\n",
            "21/21 [==============================] - 7s 320ms/step - loss: 0.6096 - accuracy: 0.6254 - val_loss: 0.6181 - val_accuracy: 0.6376\n",
            "Epoch 21/500\n",
            "21/21 [==============================] - 5s 260ms/step - loss: 0.6073 - accuracy: 0.6363 - val_loss: 0.6168 - val_accuracy: 0.6419\n",
            "Epoch 22/500\n",
            "21/21 [==============================] - 5s 244ms/step - loss: 0.6061 - accuracy: 0.6355 - val_loss: 0.6152 - val_accuracy: 0.6419\n",
            "Epoch 23/500\n",
            "21/21 [==============================] - 5s 249ms/step - loss: 0.6031 - accuracy: 0.6379 - val_loss: 0.6138 - val_accuracy: 0.6419\n",
            "Epoch 24/500\n",
            "21/21 [==============================] - 5s 256ms/step - loss: 0.6010 - accuracy: 0.6503 - val_loss: 0.6125 - val_accuracy: 0.6376\n",
            "Epoch 25/500\n",
            "21/21 [==============================] - 5s 256ms/step - loss: 0.5990 - accuracy: 0.6620 - val_loss: 0.6111 - val_accuracy: 0.6507\n",
            "Epoch 26/500\n",
            "21/21 [==============================] - 5s 239ms/step - loss: 0.5962 - accuracy: 0.6667 - val_loss: 0.6098 - val_accuracy: 0.6507\n",
            "Epoch 27/500\n",
            "21/21 [==============================] - 6s 303ms/step - loss: 0.5949 - accuracy: 0.6698 - val_loss: 0.6079 - val_accuracy: 0.6507\n",
            "Epoch 28/500\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.5916 - accuracy: 0.6713 - val_loss: 0.6067 - val_accuracy: 0.6507\n",
            "Epoch 29/500\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.5909 - accuracy: 0.6830 - val_loss: 0.6054 - val_accuracy: 0.6594\n",
            "Epoch 30/500\n",
            "21/21 [==============================] - 5s 233ms/step - loss: 0.5889 - accuracy: 0.6807 - val_loss: 0.6040 - val_accuracy: 0.6594\n",
            "Epoch 31/500\n",
            "21/21 [==============================] - 5s 235ms/step - loss: 0.5866 - accuracy: 0.6900 - val_loss: 0.6026 - val_accuracy: 0.6638\n",
            "Epoch 32/500\n",
            "21/21 [==============================] - 5s 230ms/step - loss: 0.5838 - accuracy: 0.6931 - val_loss: 0.6013 - val_accuracy: 0.6769\n",
            "Epoch 33/500\n",
            "21/21 [==============================] - 6s 258ms/step - loss: 0.5817 - accuracy: 0.7033 - val_loss: 0.5999 - val_accuracy: 0.6769\n",
            "Epoch 34/500\n",
            "21/21 [==============================] - 5s 239ms/step - loss: 0.5807 - accuracy: 0.7072 - val_loss: 0.5985 - val_accuracy: 0.6812\n",
            "Epoch 35/500\n",
            "21/21 [==============================] - 5s 240ms/step - loss: 0.5776 - accuracy: 0.6970 - val_loss: 0.5969 - val_accuracy: 0.6769\n",
            "Epoch 36/500\n",
            "21/21 [==============================] - 5s 234ms/step - loss: 0.5758 - accuracy: 0.6955 - val_loss: 0.5954 - val_accuracy: 0.6769\n",
            "Epoch 37/500\n",
            "21/21 [==============================] - 5s 223ms/step - loss: 0.5740 - accuracy: 0.6939 - val_loss: 0.5940 - val_accuracy: 0.6769\n",
            "Epoch 38/500\n",
            "21/21 [==============================] - 5s 256ms/step - loss: 0.5716 - accuracy: 0.6955 - val_loss: 0.5927 - val_accuracy: 0.6812\n",
            "Epoch 39/500\n",
            "21/21 [==============================] - 5s 234ms/step - loss: 0.5689 - accuracy: 0.7072 - val_loss: 0.5916 - val_accuracy: 0.7074\n",
            "Epoch 40/500\n",
            "21/21 [==============================] - 5s 232ms/step - loss: 0.5674 - accuracy: 0.7305 - val_loss: 0.5904 - val_accuracy: 0.7074\n",
            "Epoch 41/500\n",
            "21/21 [==============================] - 5s 245ms/step - loss: 0.5658 - accuracy: 0.7445 - val_loss: 0.5894 - val_accuracy: 0.7205\n",
            "Epoch 42/500\n",
            "21/21 [==============================] - 5s 246ms/step - loss: 0.5634 - accuracy: 0.7399 - val_loss: 0.5879 - val_accuracy: 0.7162\n",
            "Epoch 43/500\n",
            "21/21 [==============================] - 5s 226ms/step - loss: 0.5604 - accuracy: 0.7492 - val_loss: 0.5869 - val_accuracy: 0.7205\n",
            "Epoch 44/500\n",
            "21/21 [==============================] - 5s 243ms/step - loss: 0.5586 - accuracy: 0.7555 - val_loss: 0.5859 - val_accuracy: 0.7380\n",
            "Epoch 45/500\n",
            "21/21 [==============================] - 5s 234ms/step - loss: 0.5574 - accuracy: 0.7664 - val_loss: 0.5847 - val_accuracy: 0.7380\n",
            "Epoch 46/500\n",
            "21/21 [==============================] - 5s 252ms/step - loss: 0.5545 - accuracy: 0.7741 - val_loss: 0.5835 - val_accuracy: 0.7380\n",
            "Epoch 47/500\n",
            "21/21 [==============================] - 5s 227ms/step - loss: 0.5539 - accuracy: 0.7664 - val_loss: 0.5822 - val_accuracy: 0.7380\n",
            "Epoch 48/500\n",
            "21/21 [==============================] - 5s 232ms/step - loss: 0.5519 - accuracy: 0.7648 - val_loss: 0.5809 - val_accuracy: 0.7336\n",
            "Epoch 49/500\n",
            "21/21 [==============================] - 5s 240ms/step - loss: 0.5495 - accuracy: 0.7586 - val_loss: 0.5794 - val_accuracy: 0.7336\n",
            "Epoch 50/500\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.5473 - accuracy: 0.7601 - val_loss: 0.5782 - val_accuracy: 0.7336\n",
            "Epoch 51/500\n",
            "21/21 [==============================] - 5s 233ms/step - loss: 0.5446 - accuracy: 0.7617 - val_loss: 0.5772 - val_accuracy: 0.7380\n",
            "Epoch 52/500\n",
            "21/21 [==============================] - 5s 259ms/step - loss: 0.5429 - accuracy: 0.7710 - val_loss: 0.5762 - val_accuracy: 0.7380\n",
            "Epoch 53/500\n",
            "21/21 [==============================] - 5s 244ms/step - loss: 0.5408 - accuracy: 0.7889 - val_loss: 0.5754 - val_accuracy: 0.7380\n",
            "Epoch 54/500\n",
            "21/21 [==============================] - 5s 246ms/step - loss: 0.5388 - accuracy: 0.7827 - val_loss: 0.5742 - val_accuracy: 0.7380\n",
            "Epoch 55/500\n",
            "21/21 [==============================] - 5s 248ms/step - loss: 0.5363 - accuracy: 0.7921 - val_loss: 0.5732 - val_accuracy: 0.7380\n",
            "Epoch 56/500\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.5357 - accuracy: 0.7874 - val_loss: 0.5721 - val_accuracy: 0.7380\n",
            "Epoch 57/500\n",
            "21/21 [==============================] - 5s 256ms/step - loss: 0.5336 - accuracy: 0.8006 - val_loss: 0.5712 - val_accuracy: 0.7424\n",
            "Epoch 58/500\n",
            "21/21 [==============================] - 5s 246ms/step - loss: 0.5319 - accuracy: 0.8045 - val_loss: 0.5703 - val_accuracy: 0.7380\n",
            "Epoch 59/500\n",
            "21/21 [==============================] - 5s 231ms/step - loss: 0.5299 - accuracy: 0.8131 - val_loss: 0.5695 - val_accuracy: 0.7380\n",
            "Epoch 60/500\n",
            "21/21 [==============================] - 5s 214ms/step - loss: 0.5268 - accuracy: 0.8123 - val_loss: 0.5685 - val_accuracy: 0.7336\n",
            "Epoch 61/500\n",
            "21/21 [==============================] - 5s 230ms/step - loss: 0.5271 - accuracy: 0.8100 - val_loss: 0.5674 - val_accuracy: 0.7293\n",
            "Epoch 62/500\n",
            "21/21 [==============================] - 5s 229ms/step - loss: 0.5236 - accuracy: 0.8123 - val_loss: 0.5667 - val_accuracy: 0.7380\n",
            "Epoch 63/500\n",
            "21/21 [==============================] - 5s 258ms/step - loss: 0.5229 - accuracy: 0.8170 - val_loss: 0.5661 - val_accuracy: 0.7424\n",
            "Epoch 64/500\n",
            "21/21 [==============================] - 6s 268ms/step - loss: 0.5209 - accuracy: 0.8170 - val_loss: 0.5651 - val_accuracy: 0.7424\n",
            "Epoch 65/500\n",
            "21/21 [==============================] - 6s 265ms/step - loss: 0.5185 - accuracy: 0.8170 - val_loss: 0.5642 - val_accuracy: 0.7467\n",
            "Epoch 66/500\n",
            "21/21 [==============================] - 5s 232ms/step - loss: 0.5175 - accuracy: 0.8209 - val_loss: 0.5634 - val_accuracy: 0.7511\n",
            "Epoch 67/500\n",
            "21/21 [==============================] - 5s 247ms/step - loss: 0.5155 - accuracy: 0.8185 - val_loss: 0.5624 - val_accuracy: 0.7467\n",
            "Epoch 68/500\n",
            "21/21 [==============================] - 5s 244ms/step - loss: 0.5131 - accuracy: 0.8217 - val_loss: 0.5614 - val_accuracy: 0.7424\n",
            "Epoch 69/500\n",
            "21/21 [==============================] - 5s 230ms/step - loss: 0.5115 - accuracy: 0.8209 - val_loss: 0.5606 - val_accuracy: 0.7467\n",
            "Epoch 70/500\n",
            "21/21 [==============================] - 5s 246ms/step - loss: 0.5084 - accuracy: 0.8232 - val_loss: 0.5601 - val_accuracy: 0.7511\n",
            "Epoch 71/500\n",
            "21/21 [==============================] - 5s 240ms/step - loss: 0.5080 - accuracy: 0.8240 - val_loss: 0.5591 - val_accuracy: 0.7511\n",
            "Epoch 72/500\n",
            "21/21 [==============================] - 5s 221ms/step - loss: 0.5064 - accuracy: 0.8185 - val_loss: 0.5581 - val_accuracy: 0.7511\n",
            "Epoch 73/500\n",
            "21/21 [==============================] - 5s 243ms/step - loss: 0.5039 - accuracy: 0.8217 - val_loss: 0.5576 - val_accuracy: 0.7511\n",
            "Epoch 74/500\n",
            "21/21 [==============================] - 5s 217ms/step - loss: 0.5040 - accuracy: 0.8232 - val_loss: 0.5568 - val_accuracy: 0.7511\n",
            "Epoch 75/500\n",
            "21/21 [==============================] - 5s 224ms/step - loss: 0.5016 - accuracy: 0.8209 - val_loss: 0.5559 - val_accuracy: 0.7511\n",
            "Epoch 76/500\n",
            "21/21 [==============================] - 5s 237ms/step - loss: 0.4988 - accuracy: 0.8248 - val_loss: 0.5552 - val_accuracy: 0.7511\n",
            "Epoch 77/500\n",
            "21/21 [==============================] - 5s 220ms/step - loss: 0.4990 - accuracy: 0.8240 - val_loss: 0.5545 - val_accuracy: 0.7511\n",
            "Epoch 78/500\n",
            "21/21 [==============================] - 5s 237ms/step - loss: 0.4965 - accuracy: 0.8217 - val_loss: 0.5540 - val_accuracy: 0.7555\n",
            "Epoch 79/500\n",
            "21/21 [==============================] - 6s 295ms/step - loss: 0.4955 - accuracy: 0.8224 - val_loss: 0.5533 - val_accuracy: 0.7598\n",
            "Epoch 80/500\n",
            "21/21 [==============================] - 5s 229ms/step - loss: 0.4938 - accuracy: 0.8224 - val_loss: 0.5530 - val_accuracy: 0.7598\n",
            "Epoch 81/500\n",
            "21/21 [==============================] - 5s 228ms/step - loss: 0.4917 - accuracy: 0.8201 - val_loss: 0.5520 - val_accuracy: 0.7642\n",
            "Epoch 82/500\n",
            "21/21 [==============================] - 5s 223ms/step - loss: 0.4913 - accuracy: 0.8209 - val_loss: 0.5514 - val_accuracy: 0.7642\n",
            "Epoch 83/500\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.4908 - accuracy: 0.8217 - val_loss: 0.5508 - val_accuracy: 0.7598\n",
            "Epoch 84/500\n",
            "21/21 [==============================] - 5s 233ms/step - loss: 0.4879 - accuracy: 0.8217 - val_loss: 0.5503 - val_accuracy: 0.7598\n",
            "Epoch 85/500\n",
            "21/21 [==============================] - 5s 236ms/step - loss: 0.4879 - accuracy: 0.8263 - val_loss: 0.5503 - val_accuracy: 0.7598\n",
            "Epoch 86/500\n",
            "21/21 [==============================] - 5s 238ms/step - loss: 0.4848 - accuracy: 0.8240 - val_loss: 0.5502 - val_accuracy: 0.7686\n",
            "Epoch 87/500\n",
            "21/21 [==============================] - 5s 235ms/step - loss: 0.4843 - accuracy: 0.8240 - val_loss: 0.5499 - val_accuracy: 0.7686\n",
            "Epoch 88/500\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.4826 - accuracy: 0.8255 - val_loss: 0.5493 - val_accuracy: 0.7686\n",
            "Epoch 89/500\n",
            "21/21 [==============================] - 5s 249ms/step - loss: 0.4814 - accuracy: 0.8232 - val_loss: 0.5487 - val_accuracy: 0.7686\n",
            "Epoch 90/500\n",
            "21/21 [==============================] - 5s 254ms/step - loss: 0.4787 - accuracy: 0.8224 - val_loss: 0.5480 - val_accuracy: 0.7686\n",
            "Epoch 91/500\n",
            "21/21 [==============================] - 5s 247ms/step - loss: 0.4793 - accuracy: 0.8279 - val_loss: 0.5477 - val_accuracy: 0.7686\n",
            "Epoch 92/500\n",
            "21/21 [==============================] - 5s 250ms/step - loss: 0.4765 - accuracy: 0.8240 - val_loss: 0.5471 - val_accuracy: 0.7686\n",
            "Epoch 93/500\n",
            "21/21 [==============================] - 5s 239ms/step - loss: 0.4753 - accuracy: 0.8232 - val_loss: 0.5465 - val_accuracy: 0.7686\n",
            "Epoch 94/500\n",
            "21/21 [==============================] - 5s 229ms/step - loss: 0.4750 - accuracy: 0.8248 - val_loss: 0.5460 - val_accuracy: 0.7686\n",
            "Epoch 95/500\n",
            "21/21 [==============================] - 5s 243ms/step - loss: 0.4725 - accuracy: 0.8248 - val_loss: 0.5457 - val_accuracy: 0.7686\n",
            "Epoch 96/500\n",
            "21/21 [==============================] - 5s 238ms/step - loss: 0.4714 - accuracy: 0.8263 - val_loss: 0.5451 - val_accuracy: 0.7686\n",
            "Epoch 97/500\n",
            "21/21 [==============================] - 5s 249ms/step - loss: 0.4699 - accuracy: 0.8232 - val_loss: 0.5450 - val_accuracy: 0.7686\n",
            "Epoch 98/500\n",
            "21/21 [==============================] - 5s 227ms/step - loss: 0.4702 - accuracy: 0.8240 - val_loss: 0.5444 - val_accuracy: 0.7686\n",
            "Epoch 99/500\n",
            "21/21 [==============================] - 5s 216ms/step - loss: 0.4678 - accuracy: 0.8240 - val_loss: 0.5443 - val_accuracy: 0.7686\n",
            "Epoch 100/500\n",
            "21/21 [==============================] - 5s 245ms/step - loss: 0.4675 - accuracy: 0.8240 - val_loss: 0.5437 - val_accuracy: 0.7686\n",
            "Epoch 101/500\n",
            "21/21 [==============================] - 5s 239ms/step - loss: 0.4667 - accuracy: 0.8248 - val_loss: 0.5431 - val_accuracy: 0.7686\n",
            "Epoch 102/500\n",
            "21/21 [==============================] - 5s 230ms/step - loss: 0.4655 - accuracy: 0.8240 - val_loss: 0.5429 - val_accuracy: 0.7686\n",
            "Epoch 103/500\n",
            "21/21 [==============================] - 5s 248ms/step - loss: 0.4625 - accuracy: 0.8240 - val_loss: 0.5429 - val_accuracy: 0.7686\n",
            "Epoch 104/500\n",
            "21/21 [==============================] - 5s 256ms/step - loss: 0.4632 - accuracy: 0.8240 - val_loss: 0.5426 - val_accuracy: 0.7686\n",
            "Epoch 105/500\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.4623 - accuracy: 0.8263 - val_loss: 0.5420 - val_accuracy: 0.7686\n",
            "Epoch 106/500\n",
            "21/21 [==============================] - 5s 238ms/step - loss: 0.4604 - accuracy: 0.8255 - val_loss: 0.5418 - val_accuracy: 0.7686\n",
            "Epoch 107/500\n",
            "21/21 [==============================] - 5s 228ms/step - loss: 0.4590 - accuracy: 0.8255 - val_loss: 0.5419 - val_accuracy: 0.7729\n",
            "Epoch 108/500\n",
            "21/21 [==============================] - 5s 227ms/step - loss: 0.4605 - accuracy: 0.8232 - val_loss: 0.5415 - val_accuracy: 0.7729\n",
            "Epoch 109/500\n",
            "21/21 [==============================] - 5s 236ms/step - loss: 0.4576 - accuracy: 0.8232 - val_loss: 0.5407 - val_accuracy: 0.7686\n",
            "Epoch 110/500\n",
            "21/21 [==============================] - 5s 245ms/step - loss: 0.4567 - accuracy: 0.8240 - val_loss: 0.5405 - val_accuracy: 0.7686\n",
            "Epoch 111/500\n",
            "21/21 [==============================] - 5s 239ms/step - loss: 0.4556 - accuracy: 0.8255 - val_loss: 0.5402 - val_accuracy: 0.7686\n",
            "Epoch 112/500\n",
            "21/21 [==============================] - 5s 248ms/step - loss: 0.4543 - accuracy: 0.8279 - val_loss: 0.5401 - val_accuracy: 0.7686\n",
            "Epoch 113/500\n",
            "21/21 [==============================] - 5s 247ms/step - loss: 0.4538 - accuracy: 0.8271 - val_loss: 0.5396 - val_accuracy: 0.7686\n",
            "Epoch 114/500\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.4524 - accuracy: 0.8279 - val_loss: 0.5391 - val_accuracy: 0.7686\n",
            "Epoch 115/500\n",
            "21/21 [==============================] - 5s 236ms/step - loss: 0.4513 - accuracy: 0.8240 - val_loss: 0.5390 - val_accuracy: 0.7686\n",
            "Epoch 116/500\n",
            "21/21 [==============================] - 5s 246ms/step - loss: 0.4523 - accuracy: 0.8279 - val_loss: 0.5387 - val_accuracy: 0.7686\n",
            "Epoch 117/500\n",
            "21/21 [==============================] - 5s 249ms/step - loss: 0.4504 - accuracy: 0.8271 - val_loss: 0.5385 - val_accuracy: 0.7686\n",
            "Epoch 118/500\n",
            "21/21 [==============================] - 5s 223ms/step - loss: 0.4472 - accuracy: 0.8263 - val_loss: 0.5383 - val_accuracy: 0.7686\n",
            "Epoch 119/500\n",
            "21/21 [==============================] - 5s 230ms/step - loss: 0.4479 - accuracy: 0.8271 - val_loss: 0.5381 - val_accuracy: 0.7686\n",
            "Epoch 120/500\n",
            "21/21 [==============================] - 5s 248ms/step - loss: 0.4458 - accuracy: 0.8271 - val_loss: 0.5385 - val_accuracy: 0.7729\n",
            "Epoch 121/500\n",
            "21/21 [==============================] - 5s 246ms/step - loss: 0.4468 - accuracy: 0.8287 - val_loss: 0.5385 - val_accuracy: 0.7729\n",
            "Epoch 122/500\n",
            "21/21 [==============================] - 5s 244ms/step - loss: 0.4453 - accuracy: 0.8287 - val_loss: 0.5385 - val_accuracy: 0.7686\n",
            "Epoch 123/500\n",
            "21/21 [==============================] - 5s 251ms/step - loss: 0.4432 - accuracy: 0.8287 - val_loss: 0.5382 - val_accuracy: 0.7729\n",
            "Epoch 124/500\n",
            "21/21 [==============================] - 5s 243ms/step - loss: 0.4431 - accuracy: 0.8240 - val_loss: 0.5384 - val_accuracy: 0.7686\n",
            "Epoch 125/500\n",
            "21/21 [==============================] - 5s 252ms/step - loss: 0.4438 - accuracy: 0.8279 - val_loss: 0.5384 - val_accuracy: 0.7686\n",
            "Epoch 126/500\n",
            "21/21 [==============================] - 6s 311ms/step - loss: 0.4430 - accuracy: 0.8287 - val_loss: 0.5382 - val_accuracy: 0.7686\n",
            "Epoch 127/500\n",
            "21/21 [==============================] - 5s 247ms/step - loss: 0.4417 - accuracy: 0.8263 - val_loss: 0.5375 - val_accuracy: 0.7729\n",
            "Epoch 128/500\n",
            "21/21 [==============================] - 5s 253ms/step - loss: 0.4391 - accuracy: 0.8271 - val_loss: 0.5374 - val_accuracy: 0.7729\n",
            "Epoch 129/500\n",
            "21/21 [==============================] - 6s 265ms/step - loss: 0.4401 - accuracy: 0.8294 - val_loss: 0.5374 - val_accuracy: 0.7729\n",
            "Epoch 130/500\n",
            "21/21 [==============================] - 5s 260ms/step - loss: 0.4381 - accuracy: 0.8302 - val_loss: 0.5371 - val_accuracy: 0.7729\n",
            "Epoch 131/500\n",
            "21/21 [==============================] - 6s 266ms/step - loss: 0.4374 - accuracy: 0.8294 - val_loss: 0.5370 - val_accuracy: 0.7729\n",
            "Epoch 132/500\n",
            "21/21 [==============================] - 6s 282ms/step - loss: 0.4376 - accuracy: 0.8294 - val_loss: 0.5369 - val_accuracy: 0.7729\n",
            "Epoch 133/500\n",
            "21/21 [==============================] - 5s 253ms/step - loss: 0.4346 - accuracy: 0.8287 - val_loss: 0.5367 - val_accuracy: 0.7729\n",
            "Epoch 134/500\n",
            "21/21 [==============================] - 5s 257ms/step - loss: 0.4353 - accuracy: 0.8271 - val_loss: 0.5365 - val_accuracy: 0.7729\n",
            "Epoch 135/500\n",
            "21/21 [==============================] - 6s 266ms/step - loss: 0.4340 - accuracy: 0.8302 - val_loss: 0.5362 - val_accuracy: 0.7729\n",
            "Epoch 136/500\n",
            "21/21 [==============================] - 5s 255ms/step - loss: 0.4338 - accuracy: 0.8279 - val_loss: 0.5365 - val_accuracy: 0.7729\n",
            "Epoch 137/500\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.4332 - accuracy: 0.8302 - val_loss: 0.5365 - val_accuracy: 0.7729\n",
            "Epoch 138/500\n",
            "21/21 [==============================] - 5s 257ms/step - loss: 0.4332 - accuracy: 0.8287 - val_loss: 0.5362 - val_accuracy: 0.7729\n",
            "Epoch 139/500\n",
            "21/21 [==============================] - 5s 261ms/step - loss: 0.4304 - accuracy: 0.8318 - val_loss: 0.5365 - val_accuracy: 0.7686\n",
            "Epoch 140/500\n",
            "21/21 [==============================] - 5s 255ms/step - loss: 0.4318 - accuracy: 0.8287 - val_loss: 0.5367 - val_accuracy: 0.7686\n",
            "Epoch 141/500\n",
            "21/21 [==============================] - 5s 251ms/step - loss: 0.4308 - accuracy: 0.8263 - val_loss: 0.5368 - val_accuracy: 0.7686\n",
            "Epoch 142/500\n",
            "21/21 [==============================] - 5s 244ms/step - loss: 0.4302 - accuracy: 0.8271 - val_loss: 0.5365 - val_accuracy: 0.7686\n",
            "Epoch 143/500\n",
            "21/21 [==============================] - 5s 239ms/step - loss: 0.4295 - accuracy: 0.8271 - val_loss: 0.5363 - val_accuracy: 0.7686\n",
            "Epoch 144/500\n",
            "21/21 [==============================] - 5s 257ms/step - loss: 0.4302 - accuracy: 0.8271 - val_loss: 0.5369 - val_accuracy: 0.7642\n",
            "Epoch 145/500\n",
            "21/21 [==============================] - 5s 251ms/step - loss: 0.4258 - accuracy: 0.8248 - val_loss: 0.5369 - val_accuracy: 0.7642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tv_model.evaluate(test_tv_binary_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DrTsR5hk0in",
        "outputId": "1406a654-7bec-4b41-a8a7-cf340ba5f6b0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 3s 217ms/step - loss: 0.5424 - accuracy: 0.7638\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5423760414123535, 0.7638484239578247]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########## Trying convulution Netwwork ##########\n",
        "\n",
        "##############################################\n",
        "#### Merging textual and visual analysis #####\n",
        "##############################################\n",
        "\n",
        "t_lstm_lyr.trainable = True\n",
        "t_att_lyr.trainable  = True\n",
        "t_dense_lyr_1.trainable = True\n",
        "\n",
        "v_lstm_lyr.trainable = True\n",
        "v_att_lyr.trainable  = True\n",
        "v_dense_lyr_1.trainable = True\n",
        "\n",
        "\n",
        "t_x = t_mask_lyr(t_input)\n",
        "t_x = t_lstm_lyr(t_x)\n",
        "t_att_we, t_att_op = t_att_lyr(t_x)\n",
        "t_op = t_dense_lyr_1(t_att_op)\n",
        "\n",
        "v_x = v_mask_lyr(v_input)\n",
        "v_x = v_lstm_lyr(v_x)\n",
        "v_att_we, v_att_op = v_att_lyr(v_x)\n",
        "v_op = v_dense_lyr_1(v_att_op)\n",
        "\n",
        "# x = tf.keras.layers.concatenate((t_att_op, v_att_op))\n",
        "# x = tf.keras.layers.concatenate((t_op, v_op))\n",
        "\n",
        "\n",
        "t_op_reshaped = tf.keras.layers.Reshape((8,4,1))(t_op)\n",
        "v_op_reshaped = tf.keras.layers.Reshape((8,4,1))(v_op)\n",
        "\n",
        "\n",
        "op_stacked = tf.keras.layers.Concatenate()([t_op_reshaped, v_op_reshaped])\n",
        "\n",
        "x = tf.keras.layers.Conv2D(32, (1,1))(op_stacked)\n",
        "x = tf.keras.layers.Conv2D(64, (1,1))(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "# x  = tf.keras.layers.Lambda(lambda x: tf.math.multiply(x[0],x[1]))((t_op, v_op))\n",
        "\n",
        "tv_dense_1 = Dense(16, activation='softmax', name='text_visual_dense_layer_1')\n",
        "tv_dense = Dense(2, activation='softmax', name='text_visual_dense_layer')\n",
        "\n",
        "x = tv_dense_1(x)\n",
        "op = tv_dense(x)\n",
        "\n",
        "tv_model_conv = Model(inputs=[t_input, v_input], outputs=op, name='Text_Visual_Model')\n",
        "tv_model_conv.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A71yEtVortwd",
        "outputId": "04ed6a46-fca1-40b9-c12e-712bb1ca374d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Text_Visual_Model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text_input_layer (InputLayer)  [(None, 50, 300)]    0           []                               \n",
            "                                                                                                  \n",
            " v_input_layer (InputLayer)     [(None, 50, 20)]     0           []                               \n",
            "                                                                                                  \n",
            " text_masking_layer (Masking)   (None, 50, 300)      0           ['text_input_layer[0][0]']       \n",
            "                                                                                                  \n",
            " v_mask_layer (Masking)         (None, 50, 20)       0           ['v_input_layer[0][0]']          \n",
            "                                                                                                  \n",
            " text_lstm_layer_1 (LSTM)       (None, 50, 256)      570368      ['text_masking_layer[18][0]']    \n",
            "                                                                                                  \n",
            " v_lstm_layer_1 (LSTM)          (None, 50, 256)      283648      ['v_mask_layer[18][0]']          \n",
            "                                                                                                  \n",
            " attention_layer_2 (AttentionLa  ((None, 50, 1),     306         ['text_lstm_layer_1[18][0]']     \n",
            " yer)                            (None, 256))                                                     \n",
            "                                                                                                  \n",
            " attention_layer_4 (AttentionLa  ((None, 50, 1),     306         ['v_lstm_layer_1[18][0]']        \n",
            " yer)                            (None, 256))                                                     \n",
            "                                                                                                  \n",
            " text_dense_layer_1 (Dense)     (None, 32)           8224        ['attention_layer_2[18][1]']     \n",
            "                                                                                                  \n",
            " v_dense_layer_1 (Dense)        (None, 32)           8224        ['attention_layer_4[18][1]']     \n",
            "                                                                                                  \n",
            " reshape_18 (Reshape)           (None, 8, 4, 1)      0           ['text_dense_layer_1[18][0]']    \n",
            "                                                                                                  \n",
            " reshape_19 (Reshape)           (None, 8, 4, 1)      0           ['v_dense_layer_1[18][0]']       \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 8, 4, 2)      0           ['reshape_18[0][0]',             \n",
            "                                                                  'reshape_19[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 8, 4, 32)     96          ['concatenate_11[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 8, 4, 64)     2112        ['conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 2048)         0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " text_visual_dense_layer_1 (Den  (None, 16)          32784       ['flatten_3[0][0]']              \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " text_visual_dense_layer (Dense  (None, 2)           34          ['text_visual_dense_layer_1[0][0]\n",
            " )                                                               ']                               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 906,102\n",
            "Trainable params: 906,102\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tv_model_conv.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
        "tv_history_conv = tv_model_conv.fit(train_tv_binary_ds, validation_data=valid_tv_binary_ds, \n",
        "            epochs=500, callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TpMumRe7o9m",
        "outputId": "e14279b7-20b0-46f9-ed3c-15879d86888c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "21/21 [==============================] - 27s 842ms/step - loss: 0.6141 - accuracy: 0.7609 - val_loss: 0.6077 - val_accuracy: 0.7074\n",
            "Epoch 2/500\n",
            "21/21 [==============================] - 14s 653ms/step - loss: 0.5389 - accuracy: 0.7882 - val_loss: 0.5553 - val_accuracy: 0.7555\n",
            "Epoch 3/500\n",
            "21/21 [==============================] - 15s 709ms/step - loss: 0.5000 - accuracy: 0.8326 - val_loss: 0.5364 - val_accuracy: 0.7773\n",
            "Epoch 4/500\n",
            "21/21 [==============================] - 14s 647ms/step - loss: 0.4878 - accuracy: 0.8240 - val_loss: 0.5461 - val_accuracy: 0.7686\n",
            "Epoch 5/500\n",
            "21/21 [==============================] - 15s 693ms/step - loss: 0.4699 - accuracy: 0.8427 - val_loss: 0.5348 - val_accuracy: 0.7598\n",
            "Epoch 6/500\n",
            "21/21 [==============================] - 15s 721ms/step - loss: 0.4359 - accuracy: 0.8808 - val_loss: 0.5358 - val_accuracy: 0.7642\n",
            "Epoch 7/500\n",
            "21/21 [==============================] - 15s 732ms/step - loss: 0.4365 - accuracy: 0.8676 - val_loss: 0.5398 - val_accuracy: 0.7555\n",
            "Epoch 8/500\n",
            "21/21 [==============================] - 15s 727ms/step - loss: 0.4254 - accuracy: 0.8715 - val_loss: 0.5524 - val_accuracy: 0.7424\n",
            "Epoch 9/500\n",
            "21/21 [==============================] - 15s 723ms/step - loss: 0.4163 - accuracy: 0.8754 - val_loss: 0.5039 - val_accuracy: 0.7948\n",
            "Epoch 10/500\n",
            "21/21 [==============================] - 16s 759ms/step - loss: 0.3985 - accuracy: 0.8910 - val_loss: 0.5005 - val_accuracy: 0.7948\n",
            "Epoch 11/500\n",
            "21/21 [==============================] - 15s 736ms/step - loss: 0.3786 - accuracy: 0.9065 - val_loss: 0.5214 - val_accuracy: 0.7773\n",
            "Epoch 12/500\n",
            "21/21 [==============================] - 15s 738ms/step - loss: 0.3876 - accuracy: 0.8949 - val_loss: 0.5199 - val_accuracy: 0.7817\n",
            "Epoch 13/500\n",
            "21/21 [==============================] - 15s 723ms/step - loss: 0.3641 - accuracy: 0.9073 - val_loss: 0.5164 - val_accuracy: 0.7642\n",
            "Epoch 14/500\n",
            "21/21 [==============================] - 15s 720ms/step - loss: 0.3651 - accuracy: 0.9034 - val_loss: 0.5238 - val_accuracy: 0.7598\n",
            "Epoch 15/500\n",
            "21/21 [==============================] - 16s 755ms/step - loss: 0.3613 - accuracy: 0.9026 - val_loss: 0.4831 - val_accuracy: 0.7904\n",
            "Epoch 16/500\n",
            "21/21 [==============================] - 15s 721ms/step - loss: 0.3364 - accuracy: 0.9182 - val_loss: 0.4988 - val_accuracy: 0.7904\n",
            "Epoch 17/500\n",
            "21/21 [==============================] - 15s 720ms/step - loss: 0.3427 - accuracy: 0.9120 - val_loss: 0.5073 - val_accuracy: 0.7817\n",
            "Epoch 18/500\n",
            "21/21 [==============================] - 15s 694ms/step - loss: 0.3330 - accuracy: 0.9136 - val_loss: 0.5040 - val_accuracy: 0.7860\n",
            "Epoch 19/500\n",
            "21/21 [==============================] - 15s 698ms/step - loss: 0.3270 - accuracy: 0.9198 - val_loss: 0.5119 - val_accuracy: 0.7860\n",
            "Epoch 20/500\n",
            "21/21 [==============================] - 15s 692ms/step - loss: 0.3084 - accuracy: 0.9276 - val_loss: 0.5160 - val_accuracy: 0.7773\n",
            "Epoch 21/500\n",
            "21/21 [==============================] - 15s 706ms/step - loss: 0.2999 - accuracy: 0.9338 - val_loss: 0.4846 - val_accuracy: 0.8035\n",
            "Epoch 22/500\n",
            "21/21 [==============================] - 15s 709ms/step - loss: 0.2852 - accuracy: 0.9393 - val_loss: 0.5089 - val_accuracy: 0.7817\n",
            "Epoch 23/500\n",
            "21/21 [==============================] - 15s 722ms/step - loss: 0.2749 - accuracy: 0.9463 - val_loss: 0.5221 - val_accuracy: 0.7686\n",
            "Epoch 24/500\n",
            "21/21 [==============================] - 15s 714ms/step - loss: 0.2797 - accuracy: 0.9369 - val_loss: 0.4772 - val_accuracy: 0.8035\n",
            "Epoch 25/500\n",
            "21/21 [==============================] - 15s 725ms/step - loss: 0.2761 - accuracy: 0.9385 - val_loss: 0.5482 - val_accuracy: 0.7598\n",
            "Epoch 26/500\n",
            "21/21 [==============================] - 15s 717ms/step - loss: 0.2843 - accuracy: 0.9315 - val_loss: 0.5799 - val_accuracy: 0.7555\n",
            "Epoch 27/500\n",
            "21/21 [==============================] - 15s 722ms/step - loss: 0.2963 - accuracy: 0.9190 - val_loss: 0.5398 - val_accuracy: 0.7598\n",
            "Epoch 28/500\n",
            "21/21 [==============================] - 15s 724ms/step - loss: 0.2570 - accuracy: 0.9447 - val_loss: 0.5118 - val_accuracy: 0.7729\n",
            "Epoch 29/500\n",
            "21/21 [==============================] - 15s 723ms/step - loss: 0.2629 - accuracy: 0.9361 - val_loss: 0.5217 - val_accuracy: 0.7860\n",
            "Epoch 30/500\n",
            "21/21 [==============================] - 15s 718ms/step - loss: 0.2566 - accuracy: 0.9431 - val_loss: 0.5409 - val_accuracy: 0.7686\n",
            "Epoch 31/500\n",
            "21/21 [==============================] - 15s 734ms/step - loss: 0.2340 - accuracy: 0.9533 - val_loss: 0.5495 - val_accuracy: 0.7642\n",
            "Epoch 32/500\n",
            "21/21 [==============================] - 16s 774ms/step - loss: 0.2403 - accuracy: 0.9470 - val_loss: 0.5395 - val_accuracy: 0.7686\n",
            "Epoch 33/500\n",
            "21/21 [==============================] - 16s 754ms/step - loss: 0.2276 - accuracy: 0.9548 - val_loss: 0.5471 - val_accuracy: 0.7642\n",
            "Epoch 34/500\n",
            "21/21 [==============================] - 15s 723ms/step - loss: 0.2217 - accuracy: 0.9556 - val_loss: 0.5111 - val_accuracy: 0.7904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tv_model_conv.evaluate(test_tv_binary_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGaZnem69eQn",
        "outputId": "6955e33d-c222-4e9c-e417-6f2843eff8d0"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 3s 224ms/step - loss: 0.5754 - accuracy: 0.7507\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5753657817840576, 0.7507288455963135]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### T + A"
      ],
      "metadata": {
        "id": "gWHOuLbeKw2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing the data for training\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "buffer_size = 64\n",
        "batch_size = 64\n",
        "\n",
        "###################################################################\n",
        "##### Dataset for Binary Classification Text and Visual Model #####\n",
        "###################################################################\n",
        "\n",
        "train_ta_binary_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    (data_train['text'],\n",
        "                    data_train['audio']), \n",
        "                    data_train['labels']\n",
        "                )\n",
        "            ).map(lambda x,y: (x,[1, 0]) if y < 0 else (x,[0,1])).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "valid_ta_binary_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    (data_valid['text'],\n",
        "                    data_valid['audio']),\n",
        "                    data_valid['labels']\n",
        "                )\n",
        "            ).map(lambda x,y: (x,[1, 0]) if y < 0 else (x,[0,1])).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "test_ta_binary_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    (data_test['text'],\n",
        "                    data_test['audio']),\n",
        "                    data_test['labels']\n",
        "                )\n",
        "            ).map(lambda x,y: (x,[1, 0]) if y < 0 else (x,[0,1])).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "5saXpeNLKzia"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in train_ta_binary_ds.take(1):\n",
        "  print(data)"
      ],
      "metadata": {
        "id": "MbQSN3VkKzib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########## Trying convulution Netwwork ##########\n",
        "\n",
        "##############################################\n",
        "#### Merging textual and Audio analysis #####\n",
        "##############################################\n",
        "\n",
        "t_lstm_lyr.trainable = False\n",
        "t_att_lyr.trainable  = False\n",
        "t_dense_lyr_1.trainable = False\n",
        "\n",
        "a_lstm_lyr.trainable = False\n",
        "a_att_lyr.trainable  = False\n",
        "a_dense_lyr_1.trainable = False\n",
        "\n",
        "\n",
        "t_x = t_mask_lyr(t_input)\n",
        "t_x = t_lstm_lyr(t_x)\n",
        "t_att_we, t_att_op = t_att_lyr(t_x)\n",
        "t_op = t_dense_lyr_1(t_att_op)\n",
        "\n",
        "a_x = a_mask_lyr(a_input)\n",
        "a_x = a_lstm_lyr(a_x)\n",
        "a_att_we, a_att_op = a_att_lyr(a_x)\n",
        "a_op = a_dense_lyr_1(a_att_op)\n",
        "\n",
        "# x = tf.keras.layers.concatenate((t_att_op, v_att_op))\n",
        "# x = tf.keras.layers.concatenate((t_op, v_op))\n",
        "\n",
        "\n",
        "t_op_reshaped = tf.keras.layers.Reshape((8,4,1))(t_op)\n",
        "a_op_reshaped = tf.keras.layers.Reshape((8,4,1))(a_op)\n",
        "\n",
        "\n",
        "op_stacked = tf.keras.layers.Concatenate()([t_op_reshaped, a_op_reshaped])\n",
        "\n",
        "x = tf.keras.layers.Conv2D(32, (1,1))(op_stacked)\n",
        "x = tf.keras.layers.Conv2D(64, (1,1))(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "# x  = tf.keras.layers.Lambda(lambda x: tf.math.multiply(x[0],x[1]))((t_op, v_op))\n",
        "\n",
        "ta_dense_1 = Dense(16, activation='softmax', name='text_audio_dense_layer_1')\n",
        "ta_dense = Dense(2, activation='softmax', name='text_audio_dense_layer')\n",
        "\n",
        "x = ta_dense_1(x)\n",
        "op = ta_dense(x)\n",
        "\n",
        "ta_model_conv = Model(inputs=[t_input, a_input], outputs=op, name='Text_Audio_Model')\n",
        "ta_model_conv.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c808f26-38e1-4b71-ab8f-36d111c83b13",
        "id": "bVy7q5pbKzic"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Text_Audio_Model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text_input_layer (InputLayer)  [(None, 50, 300)]    0           []                               \n",
            "                                                                                                  \n",
            " a_input_layer (InputLayer)     [(None, 50, 5)]      0           []                               \n",
            "                                                                                                  \n",
            " text_masking_layer (Masking)   (None, 50, 300)      0           ['text_input_layer[0][0]']       \n",
            "                                                                                                  \n",
            " a_mask_layer (Masking)         (None, 50, 5)        0           ['a_input_layer[0][0]']          \n",
            "                                                                                                  \n",
            " text_lstm_layer_1 (LSTM)       (None, 50, 256)      570368      ['text_masking_layer[1][0]']     \n",
            "                                                                                                  \n",
            " a_lstm_layer_1 (LSTM)          (None, 50, 256)      268288      ['a_mask_layer[1][0]']           \n",
            "                                                                                                  \n",
            " attention_layer_1 (AttentionLa  ((None, 50, 1),     306         ['text_lstm_layer_1[1][0]']      \n",
            " yer)                            (None, 256))                                                     \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  ((None, 50, 1),     306         ['a_lstm_layer_1[1][0]']         \n",
            " r)                              (None, 256))                                                     \n",
            "                                                                                                  \n",
            " text_dense_layer_1 (Dense)     (None, 32)           8224        ['attention_layer_1[1][1]']      \n",
            "                                                                                                  \n",
            " a_dense_layer_1 (Dense)        (None, 32)           8224        ['attention_layer[1][1]']        \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 8, 4, 1)      0           ['text_dense_layer_1[1][0]']     \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 8, 4, 1)      0           ['a_dense_layer_1[1][0]']        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 8, 4, 2)      0           ['reshape[0][0]',                \n",
            "                                                                  'reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 8, 4, 32)     96          ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 8, 4, 64)     2112        ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2048)         0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " text_audio_dense_layer_1 (Dens  (None, 16)          32784       ['flatten[0][0]']                \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " text_audio_dense_layer (Dense)  (None, 2)           34          ['text_audio_dense_layer_1[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 890,742\n",
            "Trainable params: 35,026\n",
            "Non-trainable params: 855,716\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ta_model_conv.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
        "ta_history_conv = ta_model_conv.fit(train_ta_binary_ds, validation_data=valid_ta_binary_ds, \n",
        "            epochs=500, callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb2755ec-d106-4aa7-b52c-d57d22a01a95",
        "id": "7gjWAXPxKzid"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "21/21 [==============================] - 18s 454ms/step - loss: 0.6187 - accuracy: 0.7952 - val_loss: 0.5699 - val_accuracy: 0.7598\n",
            "Epoch 2/500\n",
            "21/21 [==============================] - 5s 227ms/step - loss: 0.4865 - accuracy: 0.8287 - val_loss: 0.5236 - val_accuracy: 0.7686\n",
            "Epoch 3/500\n",
            "21/21 [==============================] - 5s 226ms/step - loss: 0.4578 - accuracy: 0.8357 - val_loss: 0.5177 - val_accuracy: 0.7598\n",
            "Epoch 4/500\n",
            "21/21 [==============================] - 5s 236ms/step - loss: 0.4522 - accuracy: 0.8279 - val_loss: 0.5168 - val_accuracy: 0.7642\n",
            "Epoch 5/500\n",
            "21/21 [==============================] - 5s 232ms/step - loss: 0.4482 - accuracy: 0.8341 - val_loss: 0.5121 - val_accuracy: 0.7511\n",
            "Epoch 6/500\n",
            "21/21 [==============================] - 5s 250ms/step - loss: 0.4415 - accuracy: 0.8318 - val_loss: 0.5113 - val_accuracy: 0.7686\n",
            "Epoch 7/500\n",
            "21/21 [==============================] - 5s 232ms/step - loss: 0.4389 - accuracy: 0.8326 - val_loss: 0.5086 - val_accuracy: 0.7598\n",
            "Epoch 8/500\n",
            "21/21 [==============================] - 5s 229ms/step - loss: 0.4351 - accuracy: 0.8372 - val_loss: 0.5065 - val_accuracy: 0.7555\n",
            "Epoch 9/500\n",
            "21/21 [==============================] - 5s 253ms/step - loss: 0.4305 - accuracy: 0.8326 - val_loss: 0.5048 - val_accuracy: 0.7642\n",
            "Epoch 10/500\n",
            "21/21 [==============================] - 5s 249ms/step - loss: 0.4277 - accuracy: 0.8326 - val_loss: 0.5032 - val_accuracy: 0.7686\n",
            "Epoch 11/500\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.4240 - accuracy: 0.8341 - val_loss: 0.5022 - val_accuracy: 0.7686\n",
            "Epoch 12/500\n",
            "21/21 [==============================] - 5s 232ms/step - loss: 0.4219 - accuracy: 0.8326 - val_loss: 0.5028 - val_accuracy: 0.7686\n",
            "Epoch 13/500\n",
            "21/21 [==============================] - 5s 232ms/step - loss: 0.4191 - accuracy: 0.8333 - val_loss: 0.5001 - val_accuracy: 0.7686\n",
            "Epoch 14/500\n",
            "21/21 [==============================] - 5s 232ms/step - loss: 0.4162 - accuracy: 0.8326 - val_loss: 0.4991 - val_accuracy: 0.7642\n",
            "Epoch 15/500\n",
            "21/21 [==============================] - 8s 406ms/step - loss: 0.4129 - accuracy: 0.8333 - val_loss: 0.4981 - val_accuracy: 0.7642\n",
            "Epoch 16/500\n",
            "21/21 [==============================] - 5s 218ms/step - loss: 0.4112 - accuracy: 0.8380 - val_loss: 0.4976 - val_accuracy: 0.7555\n",
            "Epoch 17/500\n",
            "21/21 [==============================] - 5s 236ms/step - loss: 0.4080 - accuracy: 0.8388 - val_loss: 0.4965 - val_accuracy: 0.7555\n",
            "Epoch 18/500\n",
            "21/21 [==============================] - 5s 232ms/step - loss: 0.4054 - accuracy: 0.8388 - val_loss: 0.4971 - val_accuracy: 0.7598\n",
            "Epoch 19/500\n",
            "21/21 [==============================] - 5s 240ms/step - loss: 0.4029 - accuracy: 0.8403 - val_loss: 0.4959 - val_accuracy: 0.7598\n",
            "Epoch 20/500\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.4009 - accuracy: 0.8388 - val_loss: 0.4951 - val_accuracy: 0.7642\n",
            "Epoch 21/500\n",
            "21/21 [==============================] - 5s 229ms/step - loss: 0.3986 - accuracy: 0.8396 - val_loss: 0.4954 - val_accuracy: 0.7555\n",
            "Epoch 22/500\n",
            "21/21 [==============================] - 5s 231ms/step - loss: 0.3968 - accuracy: 0.8419 - val_loss: 0.4949 - val_accuracy: 0.7555\n",
            "Epoch 23/500\n",
            "21/21 [==============================] - 5s 238ms/step - loss: 0.3947 - accuracy: 0.8411 - val_loss: 0.4953 - val_accuracy: 0.7511\n",
            "Epoch 24/500\n",
            "21/21 [==============================] - 5s 222ms/step - loss: 0.3927 - accuracy: 0.8442 - val_loss: 0.4945 - val_accuracy: 0.7555\n",
            "Epoch 25/500\n",
            "21/21 [==============================] - 5s 240ms/step - loss: 0.3909 - accuracy: 0.8419 - val_loss: 0.4958 - val_accuracy: 0.7555\n",
            "Epoch 26/500\n",
            "21/21 [==============================] - 5s 221ms/step - loss: 0.3895 - accuracy: 0.8450 - val_loss: 0.4939 - val_accuracy: 0.7555\n",
            "Epoch 27/500\n",
            "21/21 [==============================] - 5s 228ms/step - loss: 0.3888 - accuracy: 0.8419 - val_loss: 0.4961 - val_accuracy: 0.7467\n",
            "Epoch 28/500\n",
            "21/21 [==============================] - 5s 222ms/step - loss: 0.3853 - accuracy: 0.8458 - val_loss: 0.4956 - val_accuracy: 0.7467\n",
            "Epoch 29/500\n",
            "21/21 [==============================] - 5s 232ms/step - loss: 0.3860 - accuracy: 0.8466 - val_loss: 0.4935 - val_accuracy: 0.7467\n",
            "Epoch 30/500\n",
            "21/21 [==============================] - 5s 224ms/step - loss: 0.3834 - accuracy: 0.8372 - val_loss: 0.4959 - val_accuracy: 0.7511\n",
            "Epoch 31/500\n",
            "21/21 [==============================] - 5s 228ms/step - loss: 0.3810 - accuracy: 0.8435 - val_loss: 0.4969 - val_accuracy: 0.7555\n",
            "Epoch 32/500\n",
            "21/21 [==============================] - 5s 231ms/step - loss: 0.3834 - accuracy: 0.8380 - val_loss: 0.4968 - val_accuracy: 0.7467\n",
            "Epoch 33/500\n",
            "21/21 [==============================] - 5s 238ms/step - loss: 0.3809 - accuracy: 0.8435 - val_loss: 0.4955 - val_accuracy: 0.7555\n",
            "Epoch 34/500\n",
            "21/21 [==============================] - 5s 230ms/step - loss: 0.3793 - accuracy: 0.8435 - val_loss: 0.4941 - val_accuracy: 0.7598\n",
            "Epoch 35/500\n",
            "21/21 [==============================] - 5s 231ms/step - loss: 0.3756 - accuracy: 0.8403 - val_loss: 0.4970 - val_accuracy: 0.7555\n",
            "Epoch 36/500\n",
            "21/21 [==============================] - 5s 223ms/step - loss: 0.3762 - accuracy: 0.8427 - val_loss: 0.4959 - val_accuracy: 0.7642\n",
            "Epoch 37/500\n",
            "21/21 [==============================] - 5s 228ms/step - loss: 0.3754 - accuracy: 0.8411 - val_loss: 0.4958 - val_accuracy: 0.7642\n",
            "Epoch 38/500\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.3741 - accuracy: 0.8419 - val_loss: 0.4975 - val_accuracy: 0.7598\n",
            "Epoch 39/500\n",
            "21/21 [==============================] - 5s 237ms/step - loss: 0.3726 - accuracy: 0.8450 - val_loss: 0.4993 - val_accuracy: 0.7555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ta_model_conv.evaluate(test_ta_binary_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "843e966a-333c-4415-86ff-61cada1e7284",
        "id": "9FL7TSSYKzid"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 4s 340ms/step - loss: 0.5252 - accuracy: 0.7580\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5251742601394653, 0.7580174803733826]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### T + V + A"
      ],
      "metadata": {
        "id": "Di6KNM-qPDMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing the data for training\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "buffer_size = 64\n",
        "batch_size = 64\n",
        "\n",
        "###################################################################\n",
        "##### Dataset for Binary Classification Text and Visual Model #####\n",
        "###################################################################\n",
        "\n",
        "train_tva_binary_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    (data_train['text'],\n",
        "                     data_train['vision'],\n",
        "                     data_train['audio']\n",
        "                    ), \n",
        "                    data_train['labels']\n",
        "                )\n",
        "            ).map(lambda x,y: (x,[1, 0]) if y < 0 else (x,[0,1])).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "valid_tva_binary_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    (data_valid['text'],\n",
        "                     data_valid['vision'],\n",
        "                     data_valid['audio']\n",
        "                    ),\n",
        "                    data_valid['labels']\n",
        "                )\n",
        "            ).map(lambda x,y: (x,[1, 0]) if y < 0 else (x,[0,1])).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "test_tva_binary_ds = tf.data.Dataset.from_tensor_slices(\n",
        "                (\n",
        "                    (data_test['text'],\n",
        "                     data_test['vision'],\n",
        "                     data_test['audio']\n",
        "                    ),\n",
        "                    data_test['labels']\n",
        "                )\n",
        "            ).map(lambda x,y: (x,[1, 0]) if y < 0 else (x,[0,1])).shuffle(buffer_size).batch(batch_size).prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "ZMj_t7T9NwvW"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########## Trying convulution Netwwork ##########\n",
        "\n",
        "##############################################\n",
        "#### Merging textual and Audio analysis #####\n",
        "##############################################\n",
        "\n",
        "t_lstm_lyr.trainable = False\n",
        "t_att_lyr.trainable  = False\n",
        "t_dense_lyr_1.trainable = False\n",
        "\n",
        "v_lstm_lyr.trainable = False\n",
        "v_att_lyr.trainable  = False\n",
        "v_dense_lyr_1.trainable = False\n",
        "\n",
        "a_lstm_lyr.trainable = False\n",
        "a_att_lyr.trainable  = False\n",
        "a_dense_lyr_1.trainable = False\n",
        "\n",
        "t_x = t_mask_lyr(t_input)\n",
        "t_x = t_lstm_lyr(t_x)\n",
        "t_att_we, t_att_op = t_att_lyr(t_x)\n",
        "t_op = t_dense_lyr_1(t_att_op)\n",
        "\n",
        "v_x = v_mask_lyr(v_input)\n",
        "v_x = v_lstm_lyr(v_x)\n",
        "v_att_we, v_att_op = v_att_lyr(v_x)\n",
        "v_op = v_dense_lyr_1(v_att_op)\n",
        "\n",
        "a_x = a_mask_lyr(a_input)\n",
        "a_x = a_lstm_lyr(a_x)\n",
        "a_att_we, a_att_op = a_att_lyr(a_x)\n",
        "a_op = a_dense_lyr_1(a_att_op)\n",
        "\n",
        "# x = tf.keras.layers.concatenate((t_att_op, v_att_op))\n",
        "# x = tf.keras.layers.concatenate((t_op, v_op))\n",
        "\n",
        "t_op_reshaped = tf.keras.layers.Reshape((8,4,1))(t_op)\n",
        "v_op_reshaped = tf.keras.layers.Reshape((8,4,1))(v_op)\n",
        "a_op_reshaped = tf.keras.layers.Reshape((8,4,1))(a_op)\n",
        "\n",
        "op_stacked = tf.keras.layers.Concatenate()([t_op_reshaped, v_op_reshaped, a_op_reshaped])\n",
        "\n",
        "x = tf.keras.layers.Conv2D(32, (2,2))(op_stacked)\n",
        "x = tf.keras.layers.Conv2D(64, (2,2))(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "# x  = tf.keras.layers.Lambda(lambda x: tf.math.multiply(x[0],x[1]))((t_op, v_op))\n",
        "\n",
        "tva_dense_1 = Dense(16, activation='softmax', name='text_vision_audio_dense_layer_1')\n",
        "tva_dense = Dense(2, activation='softmax', name='text_vision_audio_dense_layer')\n",
        "\n",
        "x = tva_dense_1(x)\n",
        "op = tva_dense(x)\n",
        "\n",
        "tva_model_conv = Model(inputs=[t_input, v_input, a_input], outputs=op, name='Text_Vision_Audio_Model')\n",
        "tva_model_conv.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzsegfdoPjNa",
        "outputId": "d27e2eff-e57b-449d-e518-4f753be98d0d"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Text_Vision_Audio_Model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text_input_layer (InputLayer)  [(None, 50, 300)]    0           []                               \n",
            "                                                                                                  \n",
            " v_input_layer (InputLayer)     [(None, 50, 20)]     0           []                               \n",
            "                                                                                                  \n",
            " a_input_layer (InputLayer)     [(None, 50, 5)]      0           []                               \n",
            "                                                                                                  \n",
            " text_masking_layer (Masking)   (None, 50, 300)      0           ['text_input_layer[0][0]']       \n",
            "                                                                                                  \n",
            " v_mask_layer (Masking)         (None, 50, 20)       0           ['v_input_layer[0][0]']          \n",
            "                                                                                                  \n",
            " a_mask_layer (Masking)         (None, 50, 5)        0           ['a_input_layer[0][0]']          \n",
            "                                                                                                  \n",
            " text_lstm_layer_1 (LSTM)       (None, 50, 256)      570368      ['text_masking_layer[1][0]']     \n",
            "                                                                                                  \n",
            " v_lstm_layer_1 (LSTM)          (None, 50, 256)      283648      ['v_mask_layer[1][0]']           \n",
            "                                                                                                  \n",
            " a_lstm_layer_1 (LSTM)          (None, 50, 256)      268288      ['a_mask_layer[1][0]']           \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  ((None, 50, 1),     306         ['text_lstm_layer_1[1][0]']      \n",
            " r)                              (None, 256))                                                     \n",
            "                                                                                                  \n",
            " attention_layer_1 (AttentionLa  ((None, 50, 1),     306         ['v_lstm_layer_1[1][0]']         \n",
            " yer)                            (None, 256))                                                     \n",
            "                                                                                                  \n",
            " attention_layer_2 (AttentionLa  ((None, 50, 1),     306         ['a_lstm_layer_1[1][0]']         \n",
            " yer)                            (None, 256))                                                     \n",
            "                                                                                                  \n",
            " text_dense_layer_1 (Dense)     (None, 32)           8224        ['attention_layer[1][1]']        \n",
            "                                                                                                  \n",
            " v_dense_layer_1 (Dense)        (None, 32)           8224        ['attention_layer_1[1][1]']      \n",
            "                                                                                                  \n",
            " a_dense_layer_1 (Dense)        (None, 32)           8224        ['attention_layer_2[1][1]']      \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 8, 4, 1)      0           ['text_dense_layer_1[1][0]']     \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 8, 4, 1)      0           ['v_dense_layer_1[1][0]']        \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 8, 4, 1)      0           ['a_dense_layer_1[1][0]']        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 8, 4, 3)      0           ['reshape[0][0]',                \n",
            "                                                                  'reshape_1[0][0]',              \n",
            "                                                                  'reshape_2[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 7, 3, 32)     416         ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 6, 2, 64)     8256        ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 768)          0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " text_vision_audio_dense_layer_  (None, 16)          12304       ['flatten[0][0]']                \n",
            " 1 (Dense)                                                                                        \n",
            "                                                                                                  \n",
            " text_vision_audio_dense_layer   (None, 2)           34          ['text_vision_audio_dense_layer_1\n",
            " (Dense)                                                         [0][0]']                         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,168,904\n",
            "Trainable params: 21,010\n",
            "Non-trainable params: 1,147,894\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tva_model_conv.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
        "tva_history_conv = tva_model_conv.fit(train_tva_binary_ds, validation_data=valid_tva_binary_ds, \n",
        "            epochs=500, callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R4noaX5QwWR",
        "outputId": "7ca09803-3f73-4b80-e7a4-05e61fe870e8"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "21/21 [==============================] - 25s 545ms/step - loss: 0.6518 - accuracy: 0.6160 - val_loss: 0.6075 - val_accuracy: 0.6725\n",
            "Epoch 2/500\n",
            "21/21 [==============================] - 9s 412ms/step - loss: 0.5291 - accuracy: 0.8302 - val_loss: 0.5436 - val_accuracy: 0.7424\n",
            "Epoch 3/500\n",
            "21/21 [==============================] - 7s 321ms/step - loss: 0.4803 - accuracy: 0.8333 - val_loss: 0.5327 - val_accuracy: 0.7511\n",
            "Epoch 4/500\n",
            "21/21 [==============================] - 7s 337ms/step - loss: 0.4702 - accuracy: 0.8333 - val_loss: 0.5277 - val_accuracy: 0.7642\n",
            "Epoch 5/500\n",
            "21/21 [==============================] - 7s 323ms/step - loss: 0.4622 - accuracy: 0.8380 - val_loss: 0.5240 - val_accuracy: 0.7686\n",
            "Epoch 6/500\n",
            "21/21 [==============================] - 7s 340ms/step - loss: 0.4545 - accuracy: 0.8388 - val_loss: 0.5209 - val_accuracy: 0.7642\n",
            "Epoch 7/500\n",
            "21/21 [==============================] - 7s 341ms/step - loss: 0.4490 - accuracy: 0.8372 - val_loss: 0.5184 - val_accuracy: 0.7686\n",
            "Epoch 8/500\n",
            "21/21 [==============================] - 7s 337ms/step - loss: 0.4434 - accuracy: 0.8427 - val_loss: 0.5153 - val_accuracy: 0.7598\n",
            "Epoch 9/500\n",
            "21/21 [==============================] - 8s 366ms/step - loss: 0.4392 - accuracy: 0.8403 - val_loss: 0.5129 - val_accuracy: 0.7686\n",
            "Epoch 10/500\n",
            "21/21 [==============================] - 7s 354ms/step - loss: 0.4335 - accuracy: 0.8427 - val_loss: 0.5109 - val_accuracy: 0.7686\n",
            "Epoch 11/500\n",
            "21/21 [==============================] - 7s 319ms/step - loss: 0.4301 - accuracy: 0.8481 - val_loss: 0.5099 - val_accuracy: 0.7686\n",
            "Epoch 12/500\n",
            "21/21 [==============================] - 7s 343ms/step - loss: 0.4269 - accuracy: 0.8388 - val_loss: 0.5096 - val_accuracy: 0.7686\n",
            "Epoch 13/500\n",
            "21/21 [==============================] - 7s 342ms/step - loss: 0.4192 - accuracy: 0.8520 - val_loss: 0.5089 - val_accuracy: 0.7511\n",
            "Epoch 14/500\n",
            "21/21 [==============================] - 7s 331ms/step - loss: 0.4182 - accuracy: 0.8481 - val_loss: 0.5065 - val_accuracy: 0.7598\n",
            "Epoch 15/500\n",
            "21/21 [==============================] - 7s 331ms/step - loss: 0.4148 - accuracy: 0.8450 - val_loss: 0.5054 - val_accuracy: 0.7598\n",
            "Epoch 16/500\n",
            "21/21 [==============================] - 7s 327ms/step - loss: 0.4148 - accuracy: 0.8435 - val_loss: 0.5058 - val_accuracy: 0.7467\n",
            "Epoch 17/500\n",
            "21/21 [==============================] - 7s 332ms/step - loss: 0.4100 - accuracy: 0.8489 - val_loss: 0.5047 - val_accuracy: 0.7467\n",
            "Epoch 18/500\n",
            "21/21 [==============================] - 7s 333ms/step - loss: 0.4052 - accuracy: 0.8458 - val_loss: 0.5035 - val_accuracy: 0.7555\n",
            "Epoch 19/500\n",
            "21/21 [==============================] - 7s 352ms/step - loss: 0.4049 - accuracy: 0.8512 - val_loss: 0.5028 - val_accuracy: 0.7511\n",
            "Epoch 20/500\n",
            "21/21 [==============================] - 7s 331ms/step - loss: 0.4029 - accuracy: 0.8466 - val_loss: 0.5018 - val_accuracy: 0.7729\n",
            "Epoch 21/500\n",
            "21/21 [==============================] - 7s 329ms/step - loss: 0.4016 - accuracy: 0.8505 - val_loss: 0.5015 - val_accuracy: 0.7511\n",
            "Epoch 22/500\n",
            "21/21 [==============================] - 7s 352ms/step - loss: 0.3978 - accuracy: 0.8512 - val_loss: 0.5017 - val_accuracy: 0.7555\n",
            "Epoch 23/500\n",
            "21/21 [==============================] - 7s 334ms/step - loss: 0.3977 - accuracy: 0.8489 - val_loss: 0.5008 - val_accuracy: 0.7686\n",
            "Epoch 24/500\n",
            "21/21 [==============================] - 7s 322ms/step - loss: 0.3957 - accuracy: 0.8489 - val_loss: 0.4988 - val_accuracy: 0.7642\n",
            "Epoch 25/500\n",
            "21/21 [==============================] - 8s 377ms/step - loss: 0.3943 - accuracy: 0.8505 - val_loss: 0.4987 - val_accuracy: 0.7555\n",
            "Epoch 26/500\n",
            "21/21 [==============================] - 8s 372ms/step - loss: 0.3894 - accuracy: 0.8536 - val_loss: 0.5003 - val_accuracy: 0.7555\n",
            "Epoch 27/500\n",
            "21/21 [==============================] - 8s 373ms/step - loss: 0.3903 - accuracy: 0.8497 - val_loss: 0.4993 - val_accuracy: 0.7598\n",
            "Epoch 28/500\n",
            "21/21 [==============================] - 7s 332ms/step - loss: 0.3896 - accuracy: 0.8450 - val_loss: 0.4977 - val_accuracy: 0.7555\n",
            "Epoch 29/500\n",
            "21/21 [==============================] - 7s 319ms/step - loss: 0.3863 - accuracy: 0.8512 - val_loss: 0.4975 - val_accuracy: 0.7729\n",
            "Epoch 30/500\n",
            "21/21 [==============================] - 7s 315ms/step - loss: 0.3847 - accuracy: 0.8497 - val_loss: 0.4977 - val_accuracy: 0.7598\n",
            "Epoch 31/500\n",
            "21/21 [==============================] - 6s 309ms/step - loss: 0.3848 - accuracy: 0.8536 - val_loss: 0.4974 - val_accuracy: 0.7642\n",
            "Epoch 32/500\n",
            "21/21 [==============================] - 7s 330ms/step - loss: 0.3828 - accuracy: 0.8481 - val_loss: 0.4994 - val_accuracy: 0.7555\n",
            "Epoch 33/500\n",
            "21/21 [==============================] - 7s 319ms/step - loss: 0.3797 - accuracy: 0.8528 - val_loss: 0.5000 - val_accuracy: 0.7511\n",
            "Epoch 34/500\n",
            "21/21 [==============================] - 7s 332ms/step - loss: 0.3798 - accuracy: 0.8489 - val_loss: 0.5020 - val_accuracy: 0.7555\n",
            "Epoch 35/500\n",
            "21/21 [==============================] - 7s 343ms/step - loss: 0.3755 - accuracy: 0.8466 - val_loss: 0.5028 - val_accuracy: 0.7555\n",
            "Epoch 36/500\n",
            "21/21 [==============================] - 7s 316ms/step - loss: 0.3747 - accuracy: 0.8458 - val_loss: 0.5022 - val_accuracy: 0.7598\n",
            "Epoch 37/500\n",
            "21/21 [==============================] - 7s 318ms/step - loss: 0.3731 - accuracy: 0.8505 - val_loss: 0.5045 - val_accuracy: 0.7555\n",
            "Epoch 38/500\n",
            "21/21 [==============================] - 8s 378ms/step - loss: 0.3697 - accuracy: 0.8505 - val_loss: 0.5075 - val_accuracy: 0.7424\n",
            "Epoch 39/500\n",
            "21/21 [==============================] - 7s 341ms/step - loss: 0.3724 - accuracy: 0.8458 - val_loss: 0.5059 - val_accuracy: 0.7467\n",
            "Epoch 40/500\n",
            "21/21 [==============================] - 7s 351ms/step - loss: 0.3696 - accuracy: 0.8505 - val_loss: 0.5049 - val_accuracy: 0.7467\n",
            "Epoch 41/500\n",
            "21/21 [==============================] - 7s 317ms/step - loss: 0.3668 - accuracy: 0.8505 - val_loss: 0.5067 - val_accuracy: 0.7424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tva_model_conv.evaluate(test_tva_binary_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWMHUsRuSUnm",
        "outputId": "539bc513-d86b-4c81-eacb-b5ea06172957"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 3s 255ms/step - loss: 0.5241 - accuracy: 0.7668\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5240862965583801, 0.7667638659477234]"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tva_input_raw = (data_valid['text'], data_valid['vision'], data_valid['audio'])\n",
        "valid_data_df['tva_model_conv'] = tva_model_conv.predict(tva_input_raw)[:,1] >= 0.5\n",
        "valid_data_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "KTfj4Rt550Ss",
        "outputId": "64d1eddd-0d2f-4a1b-9221-57a5eb59bdc6"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                f_name          s_time          e_time  true_labels  t_model  \\\n",
              "0    b'WKA5OygbEKI_20'  b'131.7929705'  b'133.6886621'         True     True   \n",
              "1    b'WKA5OygbEKI_21'  b'133.6886621'   b'138.976644'         True    False   \n",
              "2    b'WKA5OygbEKI_22'   b'170.544898'   b'172.729932'         True     True   \n",
              "3     b'WKA5OygbEKI_1'  b'4.432426304'  b'8.852380952'         True     True   \n",
              "4     b'WKA5OygbEKI_3'  b'45.95804989'  b'49.69954649'         True     True   \n",
              "..                 ...             ...             ...          ...      ...   \n",
              "224   b'c5xsKMxpXnc_4'  b'133.2097506'  b'135.8836735'         True     True   \n",
              "225   b'c5xsKMxpXnc_7'  b'149.3829932'  b'152.4360544'        False    False   \n",
              "226   b'c5xsKMxpXnc_6'  b'146.7290249'  b'149.3829932'        False    False   \n",
              "227   b'c5xsKMxpXnc_9'  b'156.6764172'  b'159.0609977'        False    False   \n",
              "228   b'c5xsKMxpXnc_8'  b'154.1122449'  b'156.6764172'        False    False   \n",
              "\n",
              "     v_model1  a_model1  tva_model_conv  \n",
              "0        True      True            True  \n",
              "1        True      True            True  \n",
              "2        True      True            True  \n",
              "3        True      True            True  \n",
              "4        True      True            True  \n",
              "..        ...       ...             ...  \n",
              "224      True     False            True  \n",
              "225      True      True           False  \n",
              "226      True      True           False  \n",
              "227      True      True           False  \n",
              "228      True      True           False  \n",
              "\n",
              "[229 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3fe9ef52-0951-4027-ae38-1f3d7d457162\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_name</th>\n",
              "      <th>s_time</th>\n",
              "      <th>e_time</th>\n",
              "      <th>true_labels</th>\n",
              "      <th>t_model</th>\n",
              "      <th>v_model1</th>\n",
              "      <th>a_model1</th>\n",
              "      <th>tva_model_conv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b'WKA5OygbEKI_20'</td>\n",
              "      <td>b'131.7929705'</td>\n",
              "      <td>b'133.6886621'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b'WKA5OygbEKI_21'</td>\n",
              "      <td>b'133.6886621'</td>\n",
              "      <td>b'138.976644'</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b'WKA5OygbEKI_22'</td>\n",
              "      <td>b'170.544898'</td>\n",
              "      <td>b'172.729932'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b'WKA5OygbEKI_1'</td>\n",
              "      <td>b'4.432426304'</td>\n",
              "      <td>b'8.852380952'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b'WKA5OygbEKI_3'</td>\n",
              "      <td>b'45.95804989'</td>\n",
              "      <td>b'49.69954649'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>b'c5xsKMxpXnc_4'</td>\n",
              "      <td>b'133.2097506'</td>\n",
              "      <td>b'135.8836735'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>b'c5xsKMxpXnc_7'</td>\n",
              "      <td>b'149.3829932'</td>\n",
              "      <td>b'152.4360544'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>b'c5xsKMxpXnc_6'</td>\n",
              "      <td>b'146.7290249'</td>\n",
              "      <td>b'149.3829932'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>b'c5xsKMxpXnc_9'</td>\n",
              "      <td>b'156.6764172'</td>\n",
              "      <td>b'159.0609977'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>b'c5xsKMxpXnc_8'</td>\n",
              "      <td>b'154.1122449'</td>\n",
              "      <td>b'156.6764172'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>229 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fe9ef52-0951-4027-ae38-1f3d7d457162')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3fe9ef52-0951-4027-ae38-1f3d7d457162 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3fe9ef52-0951-4027-ae38-1f3d7d457162');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(valid_data_df.true_labels == valid_data_df.tva_model_conv) / valid_data_df.tva_model_conv.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoqTjJLCBNum",
        "outputId": "37233c07-8271-43ac-d14b-eeab50bdfeda"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7641921397379913"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using attention on combination of all modalities."
      ],
      "metadata": {
        "id": "R2IDxakE2eYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########## Trying convulution Netwwork ##########\n",
        "\n",
        "##############################################\n",
        "#### Merging textual and Audio analysis #####\n",
        "##############################################\n",
        "\n",
        "t_lstm_lyr.trainable = False\n",
        "t_att_lyr.trainable  = False\n",
        "t_dense_lyr_1.trainable = False\n",
        "\n",
        "v_lstm_lyr.trainable = False\n",
        "v_att_lyr.trainable  = False\n",
        "v_dense_lyr_1.trainable = False\n",
        "\n",
        "a_lstm_lyr.trainable = False\n",
        "a_att_lyr.trainable  = False\n",
        "a_dense_lyr_1.trainable = False\n",
        "\n",
        "t_x = t_mask_lyr(t_input)\n",
        "t_x = t_lstm_lyr(t_x)\n",
        "t_att_we, t_att_op = t_att_lyr(t_x)\n",
        "t_op = t_dense_lyr_1(t_att_op)\n",
        "\n",
        "v_x = v_mask_lyr(v_input)\n",
        "v_x = v_lstm_lyr(v_x)\n",
        "v_att_we, v_att_op = v_att_lyr(v_x)\n",
        "v_op = v_dense_lyr_1(v_att_op)\n",
        "\n",
        "a_x = a_mask_lyr(a_input)\n",
        "a_x = a_lstm_lyr(a_x)\n",
        "a_att_we, a_att_op = a_att_lyr(a_x)\n",
        "a_op = a_dense_lyr_1(a_att_op)\n",
        "\n",
        "# x = tf.keras.layers.concatenate((t_att_op, v_att_op))\n",
        "# x = tf.keras.layers.concatenate((t_op, v_op))\n",
        "\n",
        "t_op_reshaped = tf.keras.layers.Reshape((1,32))(t_op)\n",
        "v_op_reshaped = tf.keras.layers.Reshape((1,32))(v_op)\n",
        "a_op_reshaped = tf.keras.layers.Reshape((1,32))(a_op)\n",
        "\n",
        "op_stacked = tf.keras.layers.Concatenate(axis=1)([t_op_reshaped, v_op_reshaped, a_op_reshaped])\n",
        "\n",
        "tva_att_lyr = AttentionLayer()\n",
        "tva_att_we, tva_att_op = tva_att_lyr(op_stacked)\n",
        "\n",
        "# x = tf.keras.layers.Conv2D(32, (2,2))(op_stacked)\n",
        "# x = tf.keras.layers.Conv2D(64, (2,2))(x)\n",
        "# x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "# x  = tf.keras.layers.Lambda(lambda x: tf.math.multiply(x[0],x[1]))((t_op, v_op))\n",
        "\n",
        "tva_dense_1 = Dense(16, activation='softmax', name='text_vision_audio_dense_layer_1')\n",
        "tva_dense = Dense(2, activation='softmax', name='text_vision_audio_dense_layer')\n",
        "\n",
        "x = tva_dense_1(tva_att_op)\n",
        "op = tva_dense(x)\n",
        "\n",
        "tva_model_att = Model(inputs=[t_input, v_input, a_input], outputs=op, name='Text_Vision_Audio_Model')\n",
        "tva_model_att.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFCelcV1Sbpv",
        "outputId": "4f408bb2-d1f5-498c-9f8d-5afc90b42bb9"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Text_Vision_Audio_Model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text_input_layer (InputLayer)  [(None, 50, 300)]    0           []                               \n",
            "                                                                                                  \n",
            " v_input_layer (InputLayer)     [(None, 50, 20)]     0           []                               \n",
            "                                                                                                  \n",
            " a_input_layer (InputLayer)     [(None, 50, 5)]      0           []                               \n",
            "                                                                                                  \n",
            " text_masking_layer (Masking)   (None, 50, 300)      0           ['text_input_layer[0][0]']       \n",
            "                                                                                                  \n",
            " v_mask_layer (Masking)         (None, 50, 20)       0           ['v_input_layer[0][0]']          \n",
            "                                                                                                  \n",
            " a_mask_layer (Masking)         (None, 50, 5)        0           ['a_input_layer[0][0]']          \n",
            "                                                                                                  \n",
            " text_lstm_layer_1 (LSTM)       (None, 50, 256)      570368      ['text_masking_layer[2][0]']     \n",
            "                                                                                                  \n",
            " v_lstm_layer_1 (LSTM)          (None, 50, 256)      283648      ['v_mask_layer[2][0]']           \n",
            "                                                                                                  \n",
            " a_lstm_layer_1 (LSTM)          (None, 50, 256)      268288      ['a_mask_layer[2][0]']           \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  ((None, 50, 1),     306         ['text_lstm_layer_1[2][0]']      \n",
            " r)                              (None, 256))                                                     \n",
            "                                                                                                  \n",
            " attention_layer_1 (AttentionLa  ((None, 50, 1),     306         ['v_lstm_layer_1[2][0]']         \n",
            " yer)                            (None, 256))                                                     \n",
            "                                                                                                  \n",
            " attention_layer_2 (AttentionLa  ((None, 50, 1),     306         ['a_lstm_layer_1[2][0]']         \n",
            " yer)                            (None, 256))                                                     \n",
            "                                                                                                  \n",
            " text_dense_layer_1 (Dense)     (None, 32)           8224        ['attention_layer[2][1]']        \n",
            "                                                                                                  \n",
            " v_dense_layer_1 (Dense)        (None, 32)           8224        ['attention_layer_1[2][1]']      \n",
            "                                                                                                  \n",
            " a_dense_layer_1 (Dense)        (None, 32)           8224        ['attention_layer_2[2][1]']      \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)            (None, 1, 32)        0           ['text_dense_layer_1[2][0]']     \n",
            "                                                                                                  \n",
            " reshape_4 (Reshape)            (None, 1, 32)        0           ['v_dense_layer_1[2][0]']        \n",
            "                                                                                                  \n",
            " reshape_5 (Reshape)            (None, 1, 32)        0           ['a_dense_layer_1[2][0]']        \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 3, 32)        0           ['reshape_3[0][0]',              \n",
            "                                                                  'reshape_4[0][0]',              \n",
            "                                                                  'reshape_5[0][0]']              \n",
            "                                                                                                  \n",
            " attention_layer_3 (AttentionLa  ((None, 3, 1),      35          ['concatenate_1[0][0]']          \n",
            " yer)                            (None, 32))                                                      \n",
            "                                                                                                  \n",
            " text_vision_audio_dense_layer_  (None, 16)          528         ['attention_layer_3[0][1]']      \n",
            " 1 (Dense)                                                                                        \n",
            "                                                                                                  \n",
            " text_vision_audio_dense_layer   (None, 2)           34          ['text_vision_audio_dense_layer_1\n",
            " (Dense)                                                         [0][0]']                         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,148,491\n",
            "Trainable params: 597\n",
            "Non-trainable params: 1,147,894\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tva_model_att.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
        "tva_history_att = tva_model_att.fit(train_tva_binary_ds, validation_data=valid_tva_binary_ds, \n",
        "            epochs=500, callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nKwp6VV3mmk",
        "outputId": "187b6291-4f38-4e9e-ac7d-b735e14ddc04"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "21/21 [==============================] - 25s 580ms/step - loss: 0.6948 - accuracy: 0.4494 - val_loss: 0.6905 - val_accuracy: 0.5240\n",
            "Epoch 2/500\n",
            "21/21 [==============================] - 7s 353ms/step - loss: 0.6867 - accuracy: 0.6970 - val_loss: 0.6831 - val_accuracy: 0.7598\n",
            "Epoch 3/500\n",
            "21/21 [==============================] - 7s 339ms/step - loss: 0.6789 - accuracy: 0.6581 - val_loss: 0.6750 - val_accuracy: 0.6026\n",
            "Epoch 4/500\n",
            "21/21 [==============================] - 7s 327ms/step - loss: 0.6708 - accuracy: 0.5763 - val_loss: 0.6673 - val_accuracy: 0.5983\n",
            "Epoch 5/500\n",
            "21/21 [==============================] - 7s 356ms/step - loss: 0.6624 - accuracy: 0.5794 - val_loss: 0.6598 - val_accuracy: 0.6026\n",
            "Epoch 6/500\n",
            "21/21 [==============================] - 7s 340ms/step - loss: 0.6532 - accuracy: 0.5888 - val_loss: 0.6520 - val_accuracy: 0.5983\n",
            "Epoch 7/500\n",
            "21/21 [==============================] - 7s 343ms/step - loss: 0.6435 - accuracy: 0.5997 - val_loss: 0.6437 - val_accuracy: 0.5983\n",
            "Epoch 8/500\n",
            "21/21 [==============================] - 8s 365ms/step - loss: 0.6326 - accuracy: 0.6301 - val_loss: 0.6357 - val_accuracy: 0.6114\n",
            "Epoch 9/500\n",
            "21/21 [==============================] - 7s 325ms/step - loss: 0.6215 - accuracy: 0.6581 - val_loss: 0.6272 - val_accuracy: 0.6376\n",
            "Epoch 10/500\n",
            "21/21 [==============================] - 7s 342ms/step - loss: 0.6097 - accuracy: 0.6877 - val_loss: 0.6182 - val_accuracy: 0.6419\n",
            "Epoch 11/500\n",
            "21/21 [==============================] - 7s 342ms/step - loss: 0.5964 - accuracy: 0.7243 - val_loss: 0.6086 - val_accuracy: 0.6681\n",
            "Epoch 12/500\n",
            "21/21 [==============================] - 7s 337ms/step - loss: 0.5826 - accuracy: 0.7726 - val_loss: 0.5992 - val_accuracy: 0.6725\n",
            "Epoch 13/500\n",
            "21/21 [==============================] - 7s 349ms/step - loss: 0.5686 - accuracy: 0.7998 - val_loss: 0.5902 - val_accuracy: 0.7424\n",
            "Epoch 14/500\n",
            "21/21 [==============================] - 7s 343ms/step - loss: 0.5549 - accuracy: 0.8193 - val_loss: 0.5815 - val_accuracy: 0.7380\n",
            "Epoch 15/500\n",
            "21/21 [==============================] - 8s 355ms/step - loss: 0.5411 - accuracy: 0.8271 - val_loss: 0.5731 - val_accuracy: 0.7511\n",
            "Epoch 16/500\n",
            "21/21 [==============================] - 7s 333ms/step - loss: 0.5278 - accuracy: 0.8310 - val_loss: 0.5652 - val_accuracy: 0.7511\n",
            "Epoch 17/500\n",
            "21/21 [==============================] - 8s 386ms/step - loss: 0.5151 - accuracy: 0.8349 - val_loss: 0.5579 - val_accuracy: 0.7511\n",
            "Epoch 18/500\n",
            "21/21 [==============================] - 8s 364ms/step - loss: 0.5033 - accuracy: 0.8333 - val_loss: 0.5516 - val_accuracy: 0.7467\n",
            "Epoch 19/500\n",
            "21/21 [==============================] - 7s 332ms/step - loss: 0.4924 - accuracy: 0.8364 - val_loss: 0.5459 - val_accuracy: 0.7380\n",
            "Epoch 20/500\n",
            "21/21 [==============================] - 8s 359ms/step - loss: 0.4825 - accuracy: 0.8364 - val_loss: 0.5408 - val_accuracy: 0.7380\n",
            "Epoch 21/500\n",
            "21/21 [==============================] - 7s 346ms/step - loss: 0.4730 - accuracy: 0.8349 - val_loss: 0.5362 - val_accuracy: 0.7424\n",
            "Epoch 22/500\n",
            "21/21 [==============================] - 7s 350ms/step - loss: 0.4638 - accuracy: 0.8364 - val_loss: 0.5319 - val_accuracy: 0.7424\n",
            "Epoch 23/500\n",
            "21/21 [==============================] - 7s 350ms/step - loss: 0.4559 - accuracy: 0.8318 - val_loss: 0.5283 - val_accuracy: 0.7380\n",
            "Epoch 24/500\n",
            "21/21 [==============================] - 8s 356ms/step - loss: 0.4484 - accuracy: 0.8326 - val_loss: 0.5250 - val_accuracy: 0.7424\n",
            "Epoch 25/500\n",
            "21/21 [==============================] - 7s 329ms/step - loss: 0.4417 - accuracy: 0.8302 - val_loss: 0.5221 - val_accuracy: 0.7424\n",
            "Epoch 26/500\n",
            "21/21 [==============================] - 7s 351ms/step - loss: 0.4356 - accuracy: 0.8310 - val_loss: 0.5197 - val_accuracy: 0.7424\n",
            "Epoch 27/500\n",
            "21/21 [==============================] - 7s 354ms/step - loss: 0.4297 - accuracy: 0.8287 - val_loss: 0.5175 - val_accuracy: 0.7424\n",
            "Epoch 28/500\n",
            "21/21 [==============================] - 8s 365ms/step - loss: 0.4245 - accuracy: 0.8279 - val_loss: 0.5155 - val_accuracy: 0.7424\n",
            "Epoch 29/500\n",
            "21/21 [==============================] - 7s 321ms/step - loss: 0.4194 - accuracy: 0.8294 - val_loss: 0.5140 - val_accuracy: 0.7380\n",
            "Epoch 30/500\n",
            "21/21 [==============================] - 7s 339ms/step - loss: 0.4152 - accuracy: 0.8287 - val_loss: 0.5128 - val_accuracy: 0.7424\n",
            "Epoch 31/500\n",
            "21/21 [==============================] - 7s 355ms/step - loss: 0.4117 - accuracy: 0.8279 - val_loss: 0.5122 - val_accuracy: 0.7380\n",
            "Epoch 32/500\n",
            "21/21 [==============================] - 7s 324ms/step - loss: 0.4085 - accuracy: 0.8287 - val_loss: 0.5113 - val_accuracy: 0.7380\n",
            "Epoch 33/500\n",
            "21/21 [==============================] - 7s 324ms/step - loss: 0.4054 - accuracy: 0.8263 - val_loss: 0.5107 - val_accuracy: 0.7380\n",
            "Epoch 34/500\n",
            "21/21 [==============================] - 7s 346ms/step - loss: 0.4025 - accuracy: 0.8294 - val_loss: 0.5102 - val_accuracy: 0.7424\n",
            "Epoch 35/500\n",
            "21/21 [==============================] - 8s 358ms/step - loss: 0.3999 - accuracy: 0.8310 - val_loss: 0.5096 - val_accuracy: 0.7380\n",
            "Epoch 36/500\n",
            "21/21 [==============================] - 7s 351ms/step - loss: 0.3973 - accuracy: 0.8326 - val_loss: 0.5094 - val_accuracy: 0.7380\n",
            "Epoch 37/500\n",
            "21/21 [==============================] - 7s 348ms/step - loss: 0.3953 - accuracy: 0.8318 - val_loss: 0.5092 - val_accuracy: 0.7380\n",
            "Epoch 38/500\n",
            "21/21 [==============================] - 7s 322ms/step - loss: 0.3931 - accuracy: 0.8294 - val_loss: 0.5094 - val_accuracy: 0.7380\n",
            "Epoch 39/500\n",
            "21/21 [==============================] - 7s 329ms/step - loss: 0.3920 - accuracy: 0.8287 - val_loss: 0.5094 - val_accuracy: 0.7380\n",
            "Epoch 40/500\n",
            "21/21 [==============================] - 7s 323ms/step - loss: 0.3899 - accuracy: 0.8318 - val_loss: 0.5094 - val_accuracy: 0.7380\n",
            "Epoch 41/500\n",
            "21/21 [==============================] - 7s 329ms/step - loss: 0.3885 - accuracy: 0.8318 - val_loss: 0.5095 - val_accuracy: 0.7380\n",
            "Epoch 42/500\n",
            "21/21 [==============================] - 7s 334ms/step - loss: 0.3875 - accuracy: 0.8349 - val_loss: 0.5096 - val_accuracy: 0.7380\n",
            "Epoch 43/500\n",
            "21/21 [==============================] - 7s 331ms/step - loss: 0.3857 - accuracy: 0.8333 - val_loss: 0.5100 - val_accuracy: 0.7380\n",
            "Epoch 44/500\n",
            "21/21 [==============================] - 7s 351ms/step - loss: 0.3850 - accuracy: 0.8318 - val_loss: 0.5103 - val_accuracy: 0.7380\n",
            "Epoch 45/500\n",
            "21/21 [==============================] - 7s 322ms/step - loss: 0.3835 - accuracy: 0.8341 - val_loss: 0.5107 - val_accuracy: 0.7380\n",
            "Epoch 46/500\n",
            "21/21 [==============================] - 7s 335ms/step - loss: 0.3824 - accuracy: 0.8326 - val_loss: 0.5111 - val_accuracy: 0.7380\n",
            "Epoch 47/500\n",
            "21/21 [==============================] - 7s 344ms/step - loss: 0.3817 - accuracy: 0.8341 - val_loss: 0.5114 - val_accuracy: 0.7424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tva_model_att.evaluate(test_tva_binary_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK0lSSmQ3y4_",
        "outputId": "8b57431c-347c-4ccf-d4c7-efb3c044f0bf"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 4s 310ms/step - loss: 0.5176 - accuracy: 0.7668\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5176010131835938, 0.7667638659477234]"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tva_input_raw = (data_valid['text'], data_valid['vision'], data_valid['audio'])\n",
        "valid_data_df['tva_model_att'] = tva_model_att.predict(tva_input_raw)[:,1] >= 0.5\n",
        "valid_data_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "s3D3zN3vDdPN",
        "outputId": "bb24ef17-bed7-4613-ca9e-669bdd1ff39e"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                f_name          s_time          e_time  true_labels  t_model  \\\n",
              "0    b'WKA5OygbEKI_20'  b'131.7929705'  b'133.6886621'         True     True   \n",
              "1    b'WKA5OygbEKI_21'  b'133.6886621'   b'138.976644'         True    False   \n",
              "2    b'WKA5OygbEKI_22'   b'170.544898'   b'172.729932'         True     True   \n",
              "3     b'WKA5OygbEKI_1'  b'4.432426304'  b'8.852380952'         True     True   \n",
              "4     b'WKA5OygbEKI_3'  b'45.95804989'  b'49.69954649'         True     True   \n",
              "..                 ...             ...             ...          ...      ...   \n",
              "224   b'c5xsKMxpXnc_4'  b'133.2097506'  b'135.8836735'         True     True   \n",
              "225   b'c5xsKMxpXnc_7'  b'149.3829932'  b'152.4360544'        False    False   \n",
              "226   b'c5xsKMxpXnc_6'  b'146.7290249'  b'149.3829932'        False    False   \n",
              "227   b'c5xsKMxpXnc_9'  b'156.6764172'  b'159.0609977'        False    False   \n",
              "228   b'c5xsKMxpXnc_8'  b'154.1122449'  b'156.6764172'        False    False   \n",
              "\n",
              "     v_model1  a_model1  tva_model_conv  tva_model_att  \n",
              "0        True      True            True           True  \n",
              "1        True      True            True           True  \n",
              "2        True      True            True           True  \n",
              "3        True      True            True           True  \n",
              "4        True      True            True           True  \n",
              "..        ...       ...             ...            ...  \n",
              "224      True     False            True           True  \n",
              "225      True      True           False          False  \n",
              "226      True      True           False          False  \n",
              "227      True      True           False          False  \n",
              "228      True      True           False          False  \n",
              "\n",
              "[229 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a48969fd-8937-46a4-8290-0ae33b778e35\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_name</th>\n",
              "      <th>s_time</th>\n",
              "      <th>e_time</th>\n",
              "      <th>true_labels</th>\n",
              "      <th>t_model</th>\n",
              "      <th>v_model1</th>\n",
              "      <th>a_model1</th>\n",
              "      <th>tva_model_conv</th>\n",
              "      <th>tva_model_att</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b'WKA5OygbEKI_20'</td>\n",
              "      <td>b'131.7929705'</td>\n",
              "      <td>b'133.6886621'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b'WKA5OygbEKI_21'</td>\n",
              "      <td>b'133.6886621'</td>\n",
              "      <td>b'138.976644'</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b'WKA5OygbEKI_22'</td>\n",
              "      <td>b'170.544898'</td>\n",
              "      <td>b'172.729932'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b'WKA5OygbEKI_1'</td>\n",
              "      <td>b'4.432426304'</td>\n",
              "      <td>b'8.852380952'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b'WKA5OygbEKI_3'</td>\n",
              "      <td>b'45.95804989'</td>\n",
              "      <td>b'49.69954649'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>b'c5xsKMxpXnc_4'</td>\n",
              "      <td>b'133.2097506'</td>\n",
              "      <td>b'135.8836735'</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>b'c5xsKMxpXnc_7'</td>\n",
              "      <td>b'149.3829932'</td>\n",
              "      <td>b'152.4360544'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>b'c5xsKMxpXnc_6'</td>\n",
              "      <td>b'146.7290249'</td>\n",
              "      <td>b'149.3829932'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>b'c5xsKMxpXnc_9'</td>\n",
              "      <td>b'156.6764172'</td>\n",
              "      <td>b'159.0609977'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>b'c5xsKMxpXnc_8'</td>\n",
              "      <td>b'154.1122449'</td>\n",
              "      <td>b'156.6764172'</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>229 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a48969fd-8937-46a4-8290-0ae33b778e35')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a48969fd-8937-46a4-8290-0ae33b778e35 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a48969fd-8937-46a4-8290-0ae33b778e35');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data_df.to_excel('output_comparison.xls')"
      ],
      "metadata": {
        "id": "rDTYzqXsDyfm"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('output_comparison.xls')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "f3Vb5lHMD-xD",
        "outputId": "1e4d52d4-1cc4-45a0-b711-53a73275e305"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_01cb2c50-d10d-4ba3-a70a-984be30152aa\", \"output_comparison.xls\", 46592)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rFLhMmIx9PJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### finidng the Threshold value\n",
        "def optimal_threshold(model, ds, threshold=[x/10 for x in range(1, 10)]):\n",
        "  y_pred = []\n",
        "  y_true = []\n",
        "  print(model.name)\n",
        "  for data in ds:\n",
        "    y_pred.append(model.predict(data[0]))\n",
        "    y_true.append(data[1])\n",
        "\n",
        "  y_pred_all = np.concatenate(y_pred)\n",
        "  y_true_all = np.concatenate(y_true)\n",
        "\n",
        "  for thres in threshold:\n",
        "    metric = tfa.metrics.F1Score(num_classes=2, threshold=thres)\n",
        "    metric.update_state(y_true_all, y_pred_all)\n",
        "    result = metric.result()\n",
        "    print(f'{thres}:{result.numpy()}')\n",
        "\n",
        "\n",
        "optimal_threshold(tva_model_att, test_tva_binary_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HvyK7dk92xz",
        "outputId": "79462b25-0b40-4852-de95-d82eedd78920"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text_Vision_Audio_Model\n",
            "0.1:[0.79044515 0.6183283 ]\n",
            "0.2:[0.8000001  0.66976744]\n",
            "0.3:[0.81481487 0.701087  ]\n",
            "0.4:[0.81127447 0.7423313 ]\n",
            "0.5:[0.7968952 0.7378965]\n",
            "0.6:[0.76666665 0.72302157]\n",
            "0.7:[0.6540881  0.71028036]\n",
            "0.8:[0.44531253 0.6533865 ]\n",
            "0.9:[0.        0.5720621]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_threshold(tva_model_conv, test_tva_binary_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ompw9ebBKUaE",
        "outputId": "d60b2acb-62a1-4202-a348-313848c1161a"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text_Vision_Audio_Model\n",
            "0.1:[0.7117371 0.6183283]\n",
            "0.2:[0.8071429 0.6183283]\n",
            "0.3:[0.80840546 0.71944445]\n",
            "0.4:[0.7897436 0.7327328]\n",
            "0.5:[0.77792734 0.7376788 ]\n",
            "0.6:[0.74787533 0.722973  ]\n",
            "0.7:[0.69018406 0.7246892 ]\n",
            "0.8:[0.         0.69548875]\n",
            "0.9:[0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "for data in test_tva_binary_ds:\n",
        "  y_pred.append(tva_model_att.predict(data[0]))\n",
        "  y_true.append(data[1])\n",
        "\n",
        "y_true_all = np.concatenate(y_true)\n",
        "y_pred_all = np.concatenate(y_pred)"
      ],
      "metadata": {
        "id": "5kyySWb5CkOF"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_yes = y_pred_all[:,1] > 0.5\n",
        "y_true_yes = y_true_all[:,1]\n",
        "sum(y_true_yes == y_pred_yes) / len(y_true_yes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_tfHoFvLGFG",
        "outputId": "23394fe7-a5df-457a-bd8d-9113aa4cb8c6"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7711370262390671"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    }
  ]
}